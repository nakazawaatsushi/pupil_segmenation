{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn00(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "\n",
    "    up7 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv6), conv5])\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv7)\n",
    "\n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv7), conv4])\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv8), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(inputs=inputs, outputs=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn01(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv4)\n",
    "\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool4)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "    \n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv6), conv4])\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv8), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(inputs=inputs, outputs=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn02(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv4), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(inputs=inputs, outputs=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fnames(paths):\n",
    "    f = open(paths)\n",
    "    data1 = f.read()\n",
    "    f.close()\n",
    "    lines = data1.split('\\n')\n",
    "    #print(len(lines))\n",
    "    # 最終行は空行なので消す\n",
    "    del(lines[len(lines)-1])\n",
    "    #print(len(lines))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fnames(fnames,fpath,fpath_mask,mask_ext):\n",
    "    fnames_img = [];\n",
    "    fnames_mask= [];\n",
    "    \n",
    "    for i in range(len(fnames)):\n",
    "        fnames_img.append(fpath + '/' + fnames[i]);\n",
    "        fnames_mask.append(fpath_mask + '/' + mask_ext + fnames[i]);\n",
    "        \n",
    "    return [fnames_img,fnames_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints01'\n",
    "    dname_outputs = 'outputs'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    \n",
    "    # Read Learning Data\n",
    "    fnames = load_fnames('data/list_train_01.txt')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    \n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) \n",
    "    \n",
    "    # Read Validation Data\n",
    "    fnames = load_fnames('data/list_valid_01.txt')\n",
    "    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    \n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 1452 training images loaded\n",
      "==> 1452 training masks loaded\n",
      "==> 527 validation images loaded\n",
      "==> 527 validation masks loaded\n"
     ]
    }
   ],
   "source": [
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing mean and standard deviation...\n",
      "==> mean: [130.65465  91.2685   76.63643]\n",
      "==> std : [55.2817   43.990963 43.113483]\n",
      "saving mean and standard deviation to stats01.npz...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 224, 224) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 224, 224) 9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 112, 112) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 112, 112) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 112, 112) 36928       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 56, 56)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 56, 56)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 56, 56)  147584      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 128, 28, 28)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 28, 28)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 256, 28, 28)  590080      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 256, 56, 56)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 384, 56, 56)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 56, 56)  442496      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 56, 56)  147584      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 112, 112 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192, 112, 112 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 112, 112) 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 112, 112) 36928       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 64, 224, 224) 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 96, 224, 224) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 224, 224) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 224, 224) 9248        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1, 224, 224)  33          conv2d_14[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,946,881\n",
      "Trainable params: 1,946,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model = create_fcn02(target_size)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.1, nesterov=True)\n",
    "    #rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    \n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "    # モデルの構造を保存\n",
    "    json_string = model.to_json()\n",
    "    fpath_architecture = os.path.join(dpath_checkpoints, fname_architecture)\n",
    "    with open(fpath_architecture, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(json_string)\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 1452 samples, validate on 527 samples\n",
      "Epoch 1/300\n",
      "1452/1452 [==============================] - 67s 46ms/step - loss: -0.0168 - dice_coef: 0.0168 - val_loss: -0.0215 - val_dice_coef: 0.0215\n",
      "Epoch 2/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.0215 - dice_coef: 0.0215 - val_loss: -0.0306 - val_dice_coef: 0.0306\n",
      "Epoch 3/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.0525 - dice_coef: 0.0525 - val_loss: -0.1105 - val_dice_coef: 0.1105\n",
      "Epoch 4/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.1839 - dice_coef: 0.1839 - val_loss: -0.2014 - val_dice_coef: 0.2014\n",
      "Epoch 5/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.2937 - dice_coef: 0.2937 - val_loss: -0.3496 - val_dice_coef: 0.3496\n",
      "Epoch 6/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.4098 - dice_coef: 0.4098 - val_loss: -0.4281 - val_dice_coef: 0.4281\n",
      "Epoch 7/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.5062 - dice_coef: 0.5062 - val_loss: -0.6019 - val_dice_coef: 0.6019\n",
      "Epoch 8/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.5835 - dice_coef: 0.5835 - val_loss: -0.6560 - val_dice_coef: 0.6560\n",
      "Epoch 9/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.6383 - dice_coef: 0.6383 - val_loss: -0.6804 - val_dice_coef: 0.6804\n",
      "Epoch 10/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.6526 - dice_coef: 0.6526 - val_loss: -0.6850 - val_dice_coef: 0.6850\n",
      "Epoch 11/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.6677 - dice_coef: 0.6677 - val_loss: -0.6431 - val_dice_coef: 0.6431\n",
      "Epoch 12/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.6615 - dice_coef: 0.6615 - val_loss: -0.6877 - val_dice_coef: 0.6877\n",
      "Epoch 13/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.6960 - dice_coef: 0.6960 - val_loss: -0.7111 - val_dice_coef: 0.7111\n",
      "Epoch 14/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7085 - dice_coef: 0.7085 - val_loss: -0.6958 - val_dice_coef: 0.6958\n",
      "Epoch 15/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.6805 - dice_coef: 0.6805 - val_loss: -0.7088 - val_dice_coef: 0.7088\n",
      "Epoch 16/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7184 - dice_coef: 0.7184 - val_loss: -0.7232 - val_dice_coef: 0.7232\n",
      "Epoch 17/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7155 - dice_coef: 0.7155 - val_loss: -0.7355 - val_dice_coef: 0.7355\n",
      "Epoch 18/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7279 - dice_coef: 0.7279 - val_loss: -0.7209 - val_dice_coef: 0.7209\n",
      "Epoch 19/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7311 - dice_coef: 0.7311 - val_loss: -0.7354 - val_dice_coef: 0.7354\n",
      "Epoch 20/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7270 - dice_coef: 0.7270 - val_loss: -0.7501 - val_dice_coef: 0.7501\n",
      "Epoch 21/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7208 - dice_coef: 0.7208 - val_loss: -0.7533 - val_dice_coef: 0.7533\n",
      "Epoch 22/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7386 - dice_coef: 0.7386 - val_loss: -0.7517 - val_dice_coef: 0.7517\n",
      "Epoch 23/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7517 - dice_coef: 0.7517 - val_loss: -0.7444 - val_dice_coef: 0.7444\n",
      "Epoch 24/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7532 - dice_coef: 0.7532 - val_loss: -0.7582 - val_dice_coef: 0.7582\n",
      "Epoch 25/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7462 - dice_coef: 0.7462 - val_loss: -0.7634 - val_dice_coef: 0.7634\n",
      "Epoch 26/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7557 - dice_coef: 0.7557 - val_loss: -0.7579 - val_dice_coef: 0.7579\n",
      "Epoch 27/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7625 - dice_coef: 0.7625 - val_loss: -0.7667 - val_dice_coef: 0.7667\n",
      "Epoch 28/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7431 - dice_coef: 0.7431 - val_loss: -0.7248 - val_dice_coef: 0.7248\n",
      "Epoch 29/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7571 - dice_coef: 0.7571 - val_loss: -0.7747 - val_dice_coef: 0.7747\n",
      "Epoch 30/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7688 - dice_coef: 0.7688 - val_loss: -0.7638 - val_dice_coef: 0.7638\n",
      "Epoch 31/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7583 - dice_coef: 0.7583 - val_loss: -0.7786 - val_dice_coef: 0.7786\n",
      "Epoch 32/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7722 - dice_coef: 0.7722 - val_loss: -0.7640 - val_dice_coef: 0.7640\n",
      "Epoch 33/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7661 - dice_coef: 0.7661 - val_loss: -0.7849 - val_dice_coef: 0.7849\n",
      "Epoch 34/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7777 - dice_coef: 0.7777 - val_loss: -0.7870 - val_dice_coef: 0.7870\n",
      "Epoch 35/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7827 - dice_coef: 0.7827 - val_loss: -0.7694 - val_dice_coef: 0.7694\n",
      "Epoch 36/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7787 - dice_coef: 0.7787 - val_loss: -0.7624 - val_dice_coef: 0.7624\n",
      "Epoch 37/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7845 - dice_coef: 0.7845 - val_loss: -0.7810 - val_dice_coef: 0.7810\n",
      "Epoch 38/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7832 - dice_coef: 0.7832 - val_loss: -0.7439 - val_dice_coef: 0.7439\n",
      "Epoch 39/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.7863 - dice_coef: 0.7863 - val_loss: -0.7773 - val_dice_coef: 0.7773\n",
      "Epoch 40/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7882 - dice_coef: 0.7882 - val_loss: -0.7606 - val_dice_coef: 0.7606\n",
      "Epoch 41/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7820 - dice_coef: 0.7820 - val_loss: -0.7698 - val_dice_coef: 0.7698\n",
      "Epoch 42/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7759 - dice_coef: 0.7759 - val_loss: -0.7213 - val_dice_coef: 0.7213\n",
      "Epoch 43/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7824 - dice_coef: 0.7824 - val_loss: -0.7897 - val_dice_coef: 0.7897\n",
      "Epoch 44/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7848 - dice_coef: 0.7848 - val_loss: -0.7891 - val_dice_coef: 0.7891\n",
      "Epoch 45/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7861 - dice_coef: 0.7861 - val_loss: -0.7993 - val_dice_coef: 0.7993\n",
      "Epoch 46/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8022 - dice_coef: 0.8022 - val_loss: -0.8056 - val_dice_coef: 0.8056\n",
      "Epoch 47/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8029 - dice_coef: 0.8029 - val_loss: -0.8075 - val_dice_coef: 0.8075\n",
      "Epoch 48/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7992 - dice_coef: 0.7992 - val_loss: -0.7609 - val_dice_coef: 0.7609\n",
      "Epoch 49/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.7950 - dice_coef: 0.7950 - val_loss: -0.8093 - val_dice_coef: 0.8093\n",
      "Epoch 50/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8030 - dice_coef: 0.8030 - val_loss: -0.8010 - val_dice_coef: 0.8010\n",
      "Epoch 51/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8009 - dice_coef: 0.8009 - val_loss: -0.8062 - val_dice_coef: 0.8062\n",
      "Epoch 52/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8050 - dice_coef: 0.8050 - val_loss: -0.8129 - val_dice_coef: 0.8129\n",
      "Epoch 53/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8091 - dice_coef: 0.8091 - val_loss: -0.7896 - val_dice_coef: 0.7896\n",
      "Epoch 54/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8059 - dice_coef: 0.8059 - val_loss: -0.7904 - val_dice_coef: 0.7904\n",
      "Epoch 55/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8011 - dice_coef: 0.8011 - val_loss: -0.8121 - val_dice_coef: 0.8121\n",
      "Epoch 56/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8129 - dice_coef: 0.8129 - val_loss: -0.8159 - val_dice_coef: 0.8159\n",
      "Epoch 57/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8137 - dice_coef: 0.8137 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 58/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.8119 - val_dice_coef: 0.8119\n",
      "Epoch 59/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8194 - dice_coef: 0.8194 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 60/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8166 - dice_coef: 0.8166 - val_loss: -0.8203 - val_dice_coef: 0.8203\n",
      "Epoch 61/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8179 - dice_coef: 0.8179 - val_loss: -0.8197 - val_dice_coef: 0.8197\n",
      "Epoch 62/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8126 - dice_coef: 0.8126 - val_loss: -0.8038 - val_dice_coef: 0.8038\n",
      "Epoch 63/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8063 - dice_coef: 0.8063 - val_loss: -0.8097 - val_dice_coef: 0.8097\n",
      "Epoch 64/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.8111 - val_dice_coef: 0.8111\n",
      "Epoch 65/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8118 - dice_coef: 0.8118 - val_loss: -0.8229 - val_dice_coef: 0.8229\n",
      "Epoch 66/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8186 - dice_coef: 0.8186 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 67/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8265 - dice_coef: 0.8265 - val_loss: -0.7959 - val_dice_coef: 0.7959\n",
      "Epoch 68/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8072 - dice_coef: 0.8072 - val_loss: -0.8016 - val_dice_coef: 0.8016\n",
      "Epoch 69/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8281 - dice_coef: 0.8281 - val_loss: -0.8255 - val_dice_coef: 0.8255\n",
      "Epoch 70/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8268 - dice_coef: 0.8268 - val_loss: -0.8205 - val_dice_coef: 0.8205\n",
      "Epoch 71/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8246 - dice_coef: 0.8246 - val_loss: -0.8260 - val_dice_coef: 0.8260\n",
      "Epoch 72/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8325 - dice_coef: 0.8325 - val_loss: -0.8260 - val_dice_coef: 0.8260\n",
      "Epoch 73/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.8143 - val_dice_coef: 0.8143\n",
      "Epoch 74/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8301 - dice_coef: 0.8301 - val_loss: -0.8219 - val_dice_coef: 0.8219\n",
      "Epoch 75/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8131 - dice_coef: 0.8131 - val_loss: -0.8135 - val_dice_coef: 0.8135\n",
      "Epoch 76/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8248 - dice_coef: 0.8248 - val_loss: -0.7896 - val_dice_coef: 0.7896\n",
      "Epoch 77/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8316 - dice_coef: 0.8316 - val_loss: -0.8072 - val_dice_coef: 0.8072\n",
      "Epoch 78/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8255 - dice_coef: 0.8255 - val_loss: -0.8317 - val_dice_coef: 0.8317\n",
      "Epoch 79/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.8292 - val_dice_coef: 0.8292\n",
      "Epoch 80/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.8254 - val_dice_coef: 0.8254\n",
      "Epoch 81/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8268 - dice_coef: 0.8268 - val_loss: -0.8067 - val_dice_coef: 0.8067\n",
      "Epoch 82/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8273 - dice_coef: 0.8273 - val_loss: -0.8292 - val_dice_coef: 0.8292\n",
      "Epoch 83/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8359 - dice_coef: 0.8359 - val_loss: -0.8179 - val_dice_coef: 0.8179\n",
      "Epoch 84/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8337 - dice_coef: 0.8337 - val_loss: -0.8343 - val_dice_coef: 0.8343\n",
      "Epoch 85/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8212 - dice_coef: 0.8212 - val_loss: -0.8205 - val_dice_coef: 0.8205\n",
      "Epoch 86/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8378 - dice_coef: 0.8378 - val_loss: -0.8180 - val_dice_coef: 0.8180\n",
      "Epoch 87/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8293 - dice_coef: 0.8293 - val_loss: -0.8315 - val_dice_coef: 0.8315\n",
      "Epoch 88/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8399 - dice_coef: 0.8399 - val_loss: -0.8345 - val_dice_coef: 0.8345\n",
      "Epoch 89/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8395 - dice_coef: 0.8395 - val_loss: -0.8338 - val_dice_coef: 0.8338\n",
      "Epoch 90/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8135 - dice_coef: 0.8135 - val_loss: -0.8240 - val_dice_coef: 0.8240\n",
      "Epoch 91/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8378 - dice_coef: 0.8378 - val_loss: -0.8308 - val_dice_coef: 0.8308\n",
      "Epoch 92/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.8385 - dice_coef: 0.8385 - val_loss: -0.8311 - val_dice_coef: 0.8311\n",
      "Epoch 93/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.8326 - val_dice_coef: 0.8326\n",
      "Epoch 94/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8400 - dice_coef: 0.8400 - val_loss: -0.8354 - val_dice_coef: 0.8354\n",
      "Epoch 95/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8418 - dice_coef: 0.8418 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 96/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8421 - dice_coef: 0.8421 - val_loss: -0.8413 - val_dice_coef: 0.8413\n",
      "Epoch 97/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8432 - dice_coef: 0.8432 - val_loss: -0.8373 - val_dice_coef: 0.8373\n",
      "Epoch 98/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8443 - dice_coef: 0.8443 - val_loss: -0.8137 - val_dice_coef: 0.8137\n",
      "Epoch 99/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.8422 - val_dice_coef: 0.8422\n",
      "Epoch 100/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8448 - dice_coef: 0.8448 - val_loss: -0.8414 - val_dice_coef: 0.8414\n",
      "Epoch 101/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8470 - dice_coef: 0.8470 - val_loss: -0.8130 - val_dice_coef: 0.8130\n",
      "Epoch 102/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8398 - dice_coef: 0.8398 - val_loss: -0.8406 - val_dice_coef: 0.8406\n",
      "Epoch 103/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8465 - dice_coef: 0.8465 - val_loss: -0.8414 - val_dice_coef: 0.8414\n",
      "Epoch 104/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8445 - dice_coef: 0.8445 - val_loss: -0.8213 - val_dice_coef: 0.8213\n",
      "Epoch 105/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.7968 - val_dice_coef: 0.7968\n",
      "Epoch 106/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8402 - dice_coef: 0.8402 - val_loss: -0.8338 - val_dice_coef: 0.8338\n",
      "Epoch 107/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.8357 - val_dice_coef: 0.8357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8475 - dice_coef: 0.8475 - val_loss: -0.8447 - val_dice_coef: 0.8447\n",
      "Epoch 109/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8401 - dice_coef: 0.8401 - val_loss: -0.8453 - val_dice_coef: 0.8453\n",
      "Epoch 110/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8297 - dice_coef: 0.8297 - val_loss: -0.8411 - val_dice_coef: 0.8411\n",
      "Epoch 111/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8459 - dice_coef: 0.8459 - val_loss: -0.8403 - val_dice_coef: 0.8403\n",
      "Epoch 112/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8474 - dice_coef: 0.8474 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 113/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8446 - dice_coef: 0.8446 - val_loss: -0.8432 - val_dice_coef: 0.8432\n",
      "Epoch 114/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8466 - dice_coef: 0.8466 - val_loss: -0.8445 - val_dice_coef: 0.8445\n",
      "Epoch 115/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8539 - dice_coef: 0.8539 - val_loss: -0.8478 - val_dice_coef: 0.8478\n",
      "Epoch 116/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8535 - dice_coef: 0.8535 - val_loss: -0.8400 - val_dice_coef: 0.8400\n",
      "Epoch 117/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8429 - dice_coef: 0.8429 - val_loss: -0.8345 - val_dice_coef: 0.8345\n",
      "Epoch 118/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8484 - dice_coef: 0.8484 - val_loss: -0.8101 - val_dice_coef: 0.8101\n",
      "Epoch 119/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8271 - dice_coef: 0.8271 - val_loss: -0.8437 - val_dice_coef: 0.8437\n",
      "Epoch 120/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8524 - dice_coef: 0.8524 - val_loss: -0.8485 - val_dice_coef: 0.8485\n",
      "Epoch 121/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.8484 - val_dice_coef: 0.8484\n",
      "Epoch 122/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8462 - dice_coef: 0.8462 - val_loss: -0.8389 - val_dice_coef: 0.8389\n",
      "Epoch 123/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.8492 - val_dice_coef: 0.8492\n",
      "Epoch 124/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.8402 - val_dice_coef: 0.8402\n",
      "Epoch 125/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8509 - dice_coef: 0.8509 - val_loss: -0.8127 - val_dice_coef: 0.8127\n",
      "Epoch 126/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.8523 - dice_coef: 0.8523 - val_loss: -0.8501 - val_dice_coef: 0.8501\n",
      "Epoch 127/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8582 - dice_coef: 0.8582 - val_loss: -0.8516 - val_dice_coef: 0.8516\n",
      "Epoch 128/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8551 - dice_coef: 0.8551 - val_loss: -0.8458 - val_dice_coef: 0.8458\n",
      "Epoch 129/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8540 - dice_coef: 0.8540 - val_loss: -0.8251 - val_dice_coef: 0.8251\n",
      "Epoch 130/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.8575 - dice_coef: 0.8575 - val_loss: -0.8424 - val_dice_coef: 0.8424\n",
      "Epoch 131/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.8443 - val_dice_coef: 0.8443\n",
      "Epoch 132/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.8574 - dice_coef: 0.8574 - val_loss: -0.8478 - val_dice_coef: 0.8478\n",
      "Epoch 133/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8540 - dice_coef: 0.8540 - val_loss: -0.8426 - val_dice_coef: 0.8426\n",
      "Epoch 134/300\n",
      "1452/1452 [==============================] - 50s 35ms/step - loss: -0.8574 - dice_coef: 0.8574 - val_loss: -0.8518 - val_dice_coef: 0.8518\n",
      "Epoch 135/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8543 - dice_coef: 0.8543 - val_loss: -0.8194 - val_dice_coef: 0.8194\n",
      "Epoch 136/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8518 - dice_coef: 0.8518 - val_loss: -0.8529 - val_dice_coef: 0.8529\n",
      "Epoch 137/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8595 - dice_coef: 0.8595 - val_loss: -0.8495 - val_dice_coef: 0.8495\n",
      "Epoch 138/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8508 - dice_coef: 0.8508 - val_loss: -0.8480 - val_dice_coef: 0.8480\n",
      "Epoch 139/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8476 - dice_coef: 0.8476 - val_loss: -0.8535 - val_dice_coef: 0.8535\n",
      "Epoch 140/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8609 - dice_coef: 0.8609 - val_loss: -0.8540 - val_dice_coef: 0.8540\n",
      "Epoch 141/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8581 - dice_coef: 0.8581 - val_loss: -0.8537 - val_dice_coef: 0.8537\n",
      "Epoch 142/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8440 - dice_coef: 0.8440 - val_loss: -0.7845 - val_dice_coef: 0.7845\n",
      "Epoch 143/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8504 - dice_coef: 0.8504 - val_loss: -0.8460 - val_dice_coef: 0.8460\n",
      "Epoch 144/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8601 - dice_coef: 0.8601 - val_loss: -0.8551 - val_dice_coef: 0.8551\n",
      "Epoch 145/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8597 - dice_coef: 0.8597 - val_loss: -0.8481 - val_dice_coef: 0.8481\n",
      "Epoch 146/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8618 - dice_coef: 0.8618 - val_loss: -0.8563 - val_dice_coef: 0.8563\n",
      "Epoch 147/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8560 - val_dice_coef: 0.8560\n",
      "Epoch 148/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8278 - val_dice_coef: 0.8278\n",
      "Epoch 149/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8544 - dice_coef: 0.8544 - val_loss: -0.8489 - val_dice_coef: 0.8489\n",
      "Epoch 150/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8633 - dice_coef: 0.8633 - val_loss: -0.8543 - val_dice_coef: 0.8543\n",
      "Epoch 151/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8626 - dice_coef: 0.8626 - val_loss: -0.8514 - val_dice_coef: 0.8514\n",
      "Epoch 152/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8631 - dice_coef: 0.8631 - val_loss: -0.8552 - val_dice_coef: 0.8552\n",
      "Epoch 153/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8569 - dice_coef: 0.8569 - val_loss: -0.8496 - val_dice_coef: 0.8496\n",
      "Epoch 154/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.8442 - val_dice_coef: 0.8442\n",
      "Epoch 155/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8565 - dice_coef: 0.8565 - val_loss: -0.8355 - val_dice_coef: 0.8355\n",
      "Epoch 156/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8637 - dice_coef: 0.8637 - val_loss: -0.8579 - val_dice_coef: 0.8579\n",
      "Epoch 157/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8647 - dice_coef: 0.8647 - val_loss: -0.8584 - val_dice_coef: 0.8584\n",
      "Epoch 158/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8640 - dice_coef: 0.8640 - val_loss: -0.8558 - val_dice_coef: 0.8558\n",
      "Epoch 159/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8665 - dice_coef: 0.8665 - val_loss: -0.8559 - val_dice_coef: 0.8559\n",
      "Epoch 160/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8634 - dice_coef: 0.8634 - val_loss: -0.8423 - val_dice_coef: 0.8423\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8562 - dice_coef: 0.8562 - val_loss: -0.8286 - val_dice_coef: 0.8286\n",
      "Epoch 162/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8642 - dice_coef: 0.8642 - val_loss: -0.8546 - val_dice_coef: 0.8546\n",
      "Epoch 163/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8670 - dice_coef: 0.8670 - val_loss: -0.8343 - val_dice_coef: 0.8343\n",
      "Epoch 164/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8606 - dice_coef: 0.8606 - val_loss: -0.8585 - val_dice_coef: 0.8585\n",
      "Epoch 165/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8671 - dice_coef: 0.8671 - val_loss: -0.8594 - val_dice_coef: 0.8594\n",
      "Epoch 166/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8636 - dice_coef: 0.8636 - val_loss: -0.8587 - val_dice_coef: 0.8587\n",
      "Epoch 167/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8657 - dice_coef: 0.8657 - val_loss: -0.8591 - val_dice_coef: 0.8591\n",
      "Epoch 168/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8588 - dice_coef: 0.8588 - val_loss: -0.8561 - val_dice_coef: 0.8561\n",
      "Epoch 169/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8668 - dice_coef: 0.8668 - val_loss: -0.8603 - val_dice_coef: 0.8603\n",
      "Epoch 170/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8663 - dice_coef: 0.8663 - val_loss: -0.8576 - val_dice_coef: 0.8576\n",
      "Epoch 171/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8559 - dice_coef: 0.8559 - val_loss: -0.8536 - val_dice_coef: 0.8536\n",
      "Epoch 172/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8646 - dice_coef: 0.8646 - val_loss: -0.8146 - val_dice_coef: 0.8146\n",
      "Epoch 173/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8664 - dice_coef: 0.8664 - val_loss: -0.8510 - val_dice_coef: 0.8510\n",
      "Epoch 174/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8687 - dice_coef: 0.8687 - val_loss: -0.8481 - val_dice_coef: 0.8481\n",
      "Epoch 175/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8593 - dice_coef: 0.8593 - val_loss: -0.8603 - val_dice_coef: 0.8603\n",
      "Epoch 176/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8678 - dice_coef: 0.8678 - val_loss: -0.8572 - val_dice_coef: 0.8572\n",
      "Epoch 177/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.8578 - val_dice_coef: 0.8578\n",
      "Epoch 178/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.8523 - val_dice_coef: 0.8523\n",
      "Epoch 179/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8672 - dice_coef: 0.8672 - val_loss: -0.8475 - val_dice_coef: 0.8475\n",
      "Epoch 180/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8704 - dice_coef: 0.8704 - val_loss: -0.8620 - val_dice_coef: 0.8620\n",
      "Epoch 181/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8700 - dice_coef: 0.8700 - val_loss: -0.8383 - val_dice_coef: 0.8383\n",
      "Epoch 182/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8722 - dice_coef: 0.8722 - val_loss: -0.8621 - val_dice_coef: 0.8621\n",
      "Epoch 183/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8725 - dice_coef: 0.8725 - val_loss: -0.8599 - val_dice_coef: 0.8599\n",
      "Epoch 184/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8659 - dice_coef: 0.8659 - val_loss: -0.8213 - val_dice_coef: 0.8213\n",
      "Epoch 185/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8677 - dice_coef: 0.8677 - val_loss: -0.8619 - val_dice_coef: 0.8619\n",
      "Epoch 186/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8573 - dice_coef: 0.8573 - val_loss: -0.8444 - val_dice_coef: 0.8444\n",
      "Epoch 187/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8512 - dice_coef: 0.8512 - val_loss: -0.8576 - val_dice_coef: 0.8576\n",
      "Epoch 188/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8608 - dice_coef: 0.8608 - val_loss: -0.8626 - val_dice_coef: 0.8626\n",
      "Epoch 189/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.8603 - val_dice_coef: 0.8603\n",
      "Epoch 190/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8756 - dice_coef: 0.8756 - val_loss: -0.8610 - val_dice_coef: 0.8610\n",
      "Epoch 191/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8736 - dice_coef: 0.8736 - val_loss: -0.8434 - val_dice_coef: 0.8434\n",
      "Epoch 192/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8717 - dice_coef: 0.8717 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 193/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8743 - dice_coef: 0.8743 - val_loss: -0.8616 - val_dice_coef: 0.8616\n",
      "Epoch 194/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8708 - dice_coef: 0.8708 - val_loss: -0.8512 - val_dice_coef: 0.8512\n",
      "Epoch 195/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8652 - dice_coef: 0.8652 - val_loss: -0.8609 - val_dice_coef: 0.8609\n",
      "Epoch 196/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8709 - dice_coef: 0.8709 - val_loss: -0.8595 - val_dice_coef: 0.8595\n",
      "Epoch 197/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8736 - dice_coef: 0.8736 - val_loss: -0.8626 - val_dice_coef: 0.8626\n",
      "Epoch 198/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8740 - dice_coef: 0.8740 - val_loss: -0.8573 - val_dice_coef: 0.8573\n",
      "Epoch 199/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8712 - dice_coef: 0.8712 - val_loss: -0.8641 - val_dice_coef: 0.8641\n",
      "Epoch 200/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.8623 - val_dice_coef: 0.8623\n",
      "Epoch 201/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8728 - dice_coef: 0.8728 - val_loss: -0.8641 - val_dice_coef: 0.8641\n",
      "Epoch 202/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8753 - dice_coef: 0.8753 - val_loss: -0.8626 - val_dice_coef: 0.8626\n",
      "Epoch 203/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.8645 - val_dice_coef: 0.8645\n",
      "Epoch 204/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8764 - dice_coef: 0.8764 - val_loss: -0.8594 - val_dice_coef: 0.8594\n",
      "Epoch 205/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8766 - dice_coef: 0.8766 - val_loss: -0.8494 - val_dice_coef: 0.8494\n",
      "Epoch 206/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8711 - dice_coef: 0.8711 - val_loss: -0.8544 - val_dice_coef: 0.8544\n",
      "Epoch 207/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8726 - dice_coef: 0.8726 - val_loss: -0.8471 - val_dice_coef: 0.8471\n",
      "Epoch 208/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8719 - dice_coef: 0.8719 - val_loss: -0.8648 - val_dice_coef: 0.8648\n",
      "Epoch 209/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8765 - dice_coef: 0.8765 - val_loss: -0.8622 - val_dice_coef: 0.8622\n",
      "Epoch 210/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8720 - dice_coef: 0.8720 - val_loss: -0.8614 - val_dice_coef: 0.8614\n",
      "Epoch 211/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8735 - dice_coef: 0.8735 - val_loss: -0.8644 - val_dice_coef: 0.8644\n",
      "Epoch 212/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8770 - dice_coef: 0.8770 - val_loss: -0.8583 - val_dice_coef: 0.8583\n",
      "Epoch 213/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.8637 - val_dice_coef: 0.8637\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8746 - dice_coef: 0.8746 - val_loss: -0.8612 - val_dice_coef: 0.8612\n",
      "Epoch 215/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8793 - dice_coef: 0.8793 - val_loss: -0.8529 - val_dice_coef: 0.8529\n",
      "Epoch 216/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8727 - dice_coef: 0.8727 - val_loss: -0.8657 - val_dice_coef: 0.8657\n",
      "Epoch 217/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8675 - dice_coef: 0.8675 - val_loss: -0.8620 - val_dice_coef: 0.8620\n",
      "Epoch 218/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.8641 - val_dice_coef: 0.8641\n",
      "Epoch 219/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8788 - dice_coef: 0.8788 - val_loss: -0.8435 - val_dice_coef: 0.8435\n",
      "Epoch 220/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8745 - dice_coef: 0.8745 - val_loss: -0.8651 - val_dice_coef: 0.8651\n",
      "Epoch 221/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.8631 - val_dice_coef: 0.8631\n",
      "Epoch 222/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8770 - dice_coef: 0.8770 - val_loss: -0.8646 - val_dice_coef: 0.8646\n",
      "Epoch 223/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8801 - dice_coef: 0.8801 - val_loss: -0.8664 - val_dice_coef: 0.8664\n",
      "Epoch 224/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8768 - dice_coef: 0.8768 - val_loss: -0.8571 - val_dice_coef: 0.8571\n",
      "Epoch 225/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8724 - dice_coef: 0.8724 - val_loss: -0.8437 - val_dice_coef: 0.8437\n",
      "Epoch 226/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8805 - dice_coef: 0.8805 - val_loss: -0.8651 - val_dice_coef: 0.8651\n",
      "Epoch 227/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8729 - dice_coef: 0.8729 - val_loss: -0.8666 - val_dice_coef: 0.8666\n",
      "Epoch 228/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8734 - dice_coef: 0.8734 - val_loss: -0.8391 - val_dice_coef: 0.8391\n",
      "Epoch 229/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8741 - dice_coef: 0.8741 - val_loss: -0.8397 - val_dice_coef: 0.8397\n",
      "Epoch 230/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8781 - dice_coef: 0.8781 - val_loss: -0.8573 - val_dice_coef: 0.8573\n",
      "Epoch 231/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8644 - val_dice_coef: 0.8644\n",
      "Epoch 232/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.8539 - val_dice_coef: 0.8539\n",
      "Epoch 233/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8703 - dice_coef: 0.8703 - val_loss: -0.8423 - val_dice_coef: 0.8423\n",
      "Epoch 234/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.8576 - val_dice_coef: 0.8576\n",
      "Epoch 235/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8795 - dice_coef: 0.8795 - val_loss: -0.8602 - val_dice_coef: 0.8602\n",
      "Epoch 236/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8804 - dice_coef: 0.8804 - val_loss: -0.8626 - val_dice_coef: 0.8626\n",
      "Epoch 237/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8796 - dice_coef: 0.8796 - val_loss: -0.8617 - val_dice_coef: 0.8617\n",
      "Epoch 238/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8798 - dice_coef: 0.8798 - val_loss: -0.8317 - val_dice_coef: 0.8317\n",
      "Epoch 239/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8773 - dice_coef: 0.8773 - val_loss: -0.8626 - val_dice_coef: 0.8626\n",
      "Epoch 240/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.8446 - val_dice_coef: 0.8446\n",
      "Epoch 241/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8815 - dice_coef: 0.8815 - val_loss: -0.8666 - val_dice_coef: 0.8666\n",
      "Epoch 242/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8824 - dice_coef: 0.8824 - val_loss: -0.8547 - val_dice_coef: 0.8547\n",
      "Epoch 243/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8817 - dice_coef: 0.8817 - val_loss: -0.8653 - val_dice_coef: 0.8653\n",
      "Epoch 244/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.8676 - val_dice_coef: 0.8676\n",
      "Epoch 245/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8751 - dice_coef: 0.8751 - val_loss: -0.8238 - val_dice_coef: 0.8238\n",
      "Epoch 246/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8757 - dice_coef: 0.8757 - val_loss: -0.8663 - val_dice_coef: 0.8663\n",
      "Epoch 247/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8822 - dice_coef: 0.8822 - val_loss: -0.8592 - val_dice_coef: 0.8592\n",
      "Epoch 248/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8676 - val_dice_coef: 0.8676\n",
      "Epoch 249/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8401 - val_dice_coef: 0.8401\n",
      "Epoch 250/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8723 - dice_coef: 0.8723 - val_loss: -0.8653 - val_dice_coef: 0.8653\n",
      "Epoch 251/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8833 - dice_coef: 0.8833 - val_loss: -0.8498 - val_dice_coef: 0.8498\n",
      "Epoch 252/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8774 - dice_coef: 0.8774 - val_loss: -0.8595 - val_dice_coef: 0.8595\n",
      "Epoch 253/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8714 - dice_coef: 0.8714 - val_loss: -0.8668 - val_dice_coef: 0.8668\n",
      "Epoch 254/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.8676 - val_dice_coef: 0.8676\n",
      "Epoch 255/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8849 - dice_coef: 0.8849 - val_loss: -0.8687 - val_dice_coef: 0.8687\n",
      "Epoch 256/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8853 - dice_coef: 0.8853 - val_loss: -0.8672 - val_dice_coef: 0.8672\n",
      "Epoch 257/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8703 - dice_coef: 0.8703 - val_loss: -0.8551 - val_dice_coef: 0.8551\n",
      "Epoch 258/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8805 - dice_coef: 0.8805 - val_loss: -0.8602 - val_dice_coef: 0.8602\n",
      "Epoch 259/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8831 - dice_coef: 0.8831 - val_loss: -0.8641 - val_dice_coef: 0.8641\n",
      "Epoch 260/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8852 - dice_coef: 0.8852 - val_loss: -0.8655 - val_dice_coef: 0.8655\n",
      "Epoch 261/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.8642 - val_dice_coef: 0.8642\n",
      "Epoch 262/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8870 - dice_coef: 0.8870 - val_loss: -0.8685 - val_dice_coef: 0.8685\n",
      "Epoch 263/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8843 - dice_coef: 0.8843 - val_loss: -0.8666 - val_dice_coef: 0.8666\n",
      "Epoch 264/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8863 - dice_coef: 0.8863 - val_loss: -0.8685 - val_dice_coef: 0.8685\n",
      "Epoch 265/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8853 - dice_coef: 0.8853 - val_loss: -0.8664 - val_dice_coef: 0.8664\n",
      "Epoch 266/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8766 - dice_coef: 0.8766 - val_loss: -0.8582 - val_dice_coef: 0.8582\n",
      "Epoch 267/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8868 - dice_coef: 0.8868 - val_loss: -0.8352 - val_dice_coef: 0.8352\n",
      "Epoch 268/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8837 - dice_coef: 0.8837 - val_loss: -0.8598 - val_dice_coef: 0.8598\n",
      "Epoch 269/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8861 - dice_coef: 0.8861 - val_loss: -0.8612 - val_dice_coef: 0.8612\n",
      "Epoch 270/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.8565 - val_dice_coef: 0.8565\n",
      "Epoch 271/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8866 - dice_coef: 0.8866 - val_loss: -0.8687 - val_dice_coef: 0.8687\n",
      "Epoch 272/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.8535 - val_dice_coef: 0.8535\n",
      "Epoch 273/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8848 - dice_coef: 0.8848 - val_loss: -0.8541 - val_dice_coef: 0.8541\n",
      "Epoch 274/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.8679 - val_dice_coef: 0.8679\n",
      "Epoch 275/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8892 - dice_coef: 0.8892 - val_loss: -0.8691 - val_dice_coef: 0.8691\n",
      "Epoch 276/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8766 - dice_coef: 0.8766 - val_loss: -0.8281 - val_dice_coef: 0.8281\n",
      "Epoch 277/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8812 - dice_coef: 0.8812 - val_loss: -0.8616 - val_dice_coef: 0.8616\n",
      "Epoch 278/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8846 - dice_coef: 0.8846 - val_loss: -0.8496 - val_dice_coef: 0.8496\n",
      "Epoch 279/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8879 - dice_coef: 0.8879 - val_loss: -0.8653 - val_dice_coef: 0.8653\n",
      "Epoch 280/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.8627 - val_dice_coef: 0.8627\n",
      "Epoch 281/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8901 - dice_coef: 0.8901 - val_loss: -0.8532 - val_dice_coef: 0.8532\n",
      "Epoch 282/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8864 - dice_coef: 0.8864 - val_loss: -0.8695 - val_dice_coef: 0.8695\n",
      "Epoch 283/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8893 - dice_coef: 0.8893 - val_loss: -0.8693 - val_dice_coef: 0.8693\n",
      "Epoch 284/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8895 - dice_coef: 0.8895 - val_loss: -0.8697 - val_dice_coef: 0.8697\n",
      "Epoch 285/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8838 - dice_coef: 0.8838 - val_loss: -0.8483 - val_dice_coef: 0.8483\n",
      "Epoch 286/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8860 - dice_coef: 0.8860 - val_loss: -0.8654 - val_dice_coef: 0.8654\n",
      "Epoch 287/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.8686 - val_dice_coef: 0.8686\n",
      "Epoch 288/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8897 - dice_coef: 0.8897 - val_loss: -0.8642 - val_dice_coef: 0.8642\n",
      "Epoch 289/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.8690 - val_dice_coef: 0.8690\n",
      "Epoch 290/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8887 - dice_coef: 0.8887 - val_loss: -0.8641 - val_dice_coef: 0.8641\n",
      "Epoch 291/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8902 - dice_coef: 0.8902 - val_loss: -0.8634 - val_dice_coef: 0.8634\n",
      "Epoch 292/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8821 - dice_coef: 0.8821 - val_loss: -0.8696 - val_dice_coef: 0.8696\n",
      "Epoch 293/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8771 - dice_coef: 0.8771 - val_loss: -0.8678 - val_dice_coef: 0.8678\n",
      "Epoch 294/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8884 - dice_coef: 0.8884 - val_loss: -0.8705 - val_dice_coef: 0.8705\n",
      "Epoch 295/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8918 - dice_coef: 0.8918 - val_loss: -0.8622 - val_dice_coef: 0.8622\n",
      "Epoch 296/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8923 - dice_coef: 0.8923 - val_loss: -0.8571 - val_dice_coef: 0.8571\n",
      "Epoch 297/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8896 - dice_coef: 0.8896 - val_loss: -0.8581 - val_dice_coef: 0.8581\n",
      "Epoch 298/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8862 - dice_coef: 0.8862 - val_loss: -0.8701 - val_dice_coef: 0.8701\n",
      "Epoch 299/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8904 - dice_coef: 0.8904 - val_loss: -0.8564 - val_dice_coef: 0.8564\n",
      "Epoch 300/300\n",
      "1452/1452 [==============================] - 50s 34ms/step - loss: -0.8886 - dice_coef: 0.8886 - val_loss: -0.8704 - val_dice_coef: 0.8704\n"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    history = model.fit(X_train, Y_train, batch_size=32, epochs=300, verbose=1,\n",
    "                  shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.callbacks.History object at 0x7f6961c2c400>\n"
     ]
    }
   ],
   "source": [
    "    print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't pickle _thread.lock objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ce008fcaa1ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'history.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.lock objects"
     ]
    }
   ],
   "source": [
    "    import pickle\n",
    "    \n",
    "    f = open('history.pkl','w')\n",
    "    pickle.dump(history.history,f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
