{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn00(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv5)\n",
    "\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool5)\n",
    "    conv6 = Conv2D(1024, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "\n",
    "    up7 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv6), conv5])\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(up7)\n",
    "    conv7 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv7)\n",
    "\n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv7), conv4])\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv8), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(inputs=inputs, outputs=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn01(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv4)\n",
    "\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool4)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv6)\n",
    "    \n",
    "    up8 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv6), conv4])\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(up8)\n",
    "    conv8 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv8)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv8), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(inputs=inputs, outputs=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_fcn02(input_size):\n",
    "    inputs = Input((3, input_size[1], input_size[0]))\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_first')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv4)\n",
    "\n",
    "    up9 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv4), conv3])\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(up9)\n",
    "    conv9 = Conv2D(128, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv9)\n",
    "\n",
    "    up10 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv9), conv2])\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(up10)\n",
    "    conv10 = Conv2D(64, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv10)\n",
    "\n",
    "    up11 = Concatenate(axis=1)([UpSampling2D(size=(2, 2), data_format='channels_first')(conv10), conv1])\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(up11)\n",
    "    conv11 = Conv2D(32, (3, 3), activation='relu', padding='same', data_format='channels_first')(conv11)\n",
    "\n",
    "    conv12 = Conv2D(1, (1, 1), activation='sigmoid', padding='same', data_format='channels_first')(conv11)\n",
    "    #conv12 = Conv2D(1, 1, 1)(conv11)\n",
    "    \n",
    "    fcn = Model(inputs=inputs, outputs=conv12)\n",
    "\n",
    "    return fcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fnames(paths):\n",
    "    f = open(paths)\n",
    "    data1 = f.read()\n",
    "    f.close()\n",
    "    lines = data1.split('\\n')\n",
    "    #print(len(lines))\n",
    "    # 最終行は空行なので消す\n",
    "    del(lines[len(lines)-1])\n",
    "    #print(len(lines))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fnames(fnames,fpath,fpath_mask,mask_ext):\n",
    "    fnames_img = [];\n",
    "    fnames_mask= [];\n",
    "    \n",
    "    for i in range(len(fnames)):\n",
    "        fnames_img.append(fpath + '/' + fnames[i]);\n",
    "        fnames_mask.append(fpath_mask + '/' + mask_ext + fnames[i]);\n",
    "        \n",
    "    return [fnames_img,fnames_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints01'\n",
    "    dname_outputs = 'outputs'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    \n",
    "    # Read Learning Data\n",
    "    fnames = load_fnames('data/list_train_01.txt')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    \n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) \n",
    "    \n",
    "    # Read Validation Data\n",
    "    fnames = load_fnames('data/list_valid_01.txt')\n",
    "    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    \n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 1452 training images loaded\n",
      "==> 1452 training masks loaded\n",
      "==> 527 validation images loaded\n",
      "==> 527 validation masks loaded\n"
     ]
    }
   ],
   "source": [
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing mean and standard deviation...\n",
      "==> mean: [130.65465  91.2685   76.63643]\n",
      "==> std : [55.2817   43.990963 43.113483]\n",
      "saving mean and standard deviation to stats01.npz...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 32, 224, 224) 896         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 32, 224, 224) 9248        conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 32, 112, 112) 0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 64, 112, 112) 18496       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 64, 112, 112) 36928       conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 64, 56, 56)   0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 128, 56, 56)  73856       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 128, 56, 56)  147584      conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 128, 28, 28)  0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 256, 28, 28)  295168      max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 256, 28, 28)  590080      conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 256, 56, 56)  0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 384, 56, 56)  0           up_sampling2d_15[0][0]           \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 128, 56, 56)  442496      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 128, 56, 56)  147584      conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, 128, 112, 112 0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 192, 112, 112 0           up_sampling2d_16[0][0]           \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 112, 112) 110656      concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 64, 112, 112) 36928       conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 64, 224, 224) 0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 96, 224, 224) 0           up_sampling2d_17[0][0]           \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 224, 224) 27680       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 224, 224) 9248        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 224, 224)  33          conv2d_79[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,946,881\n",
      "Trainable params: 1,946,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model = create_fcn02(target_size)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.1, nesterov=True)\n",
    "    #rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    \n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "    # モデルの構造を保存\n",
    "    json_string = model.to_json()\n",
    "    fpath_architecture = os.path.join(dpath_checkpoints, fname_architecture)\n",
    "    with open(fpath_architecture, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(json_string)\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 1452 samples, validate on 527 samples\n",
      "Epoch 1/100\n",
      "1452/1452 [==============================] - 51s 35ms/step - loss: -0.0157 - dice_coef: 0.0157 - val_loss: -0.0196 - val_dice_coef: 0.0196\n",
      "Epoch 2/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.0186 - dice_coef: 0.0186 - val_loss: -0.0266 - val_dice_coef: 0.0266\n",
      "Epoch 3/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.0570 - dice_coef: 0.0570 - val_loss: -0.1459 - val_dice_coef: 0.1459\n",
      "Epoch 4/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.1982 - dice_coef: 0.1982 - val_loss: -0.2972 - val_dice_coef: 0.2972\n",
      "Epoch 5/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.3202 - dice_coef: 0.3202 - val_loss: -0.3813 - val_dice_coef: 0.3813\n",
      "Epoch 6/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.4233 - dice_coef: 0.4233 - val_loss: -0.3689 - val_dice_coef: 0.3689\n",
      "Epoch 7/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.5223 - dice_coef: 0.5223 - val_loss: -0.5613 - val_dice_coef: 0.5613\n",
      "Epoch 8/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.5857 - dice_coef: 0.5857 - val_loss: -0.5162 - val_dice_coef: 0.5162\n",
      "Epoch 9/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6161 - dice_coef: 0.6161 - val_loss: -0.6093 - val_dice_coef: 0.6093\n",
      "Epoch 10/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6071 - dice_coef: 0.6071 - val_loss: -0.6715 - val_dice_coef: 0.6715\n",
      "Epoch 11/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6492 - dice_coef: 0.6492 - val_loss: -0.6279 - val_dice_coef: 0.6279\n",
      "Epoch 12/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6540 - dice_coef: 0.6540 - val_loss: -0.6613 - val_dice_coef: 0.6613\n",
      "Epoch 13/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6698 - dice_coef: 0.6698 - val_loss: -0.6952 - val_dice_coef: 0.6952\n",
      "Epoch 14/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6832 - dice_coef: 0.6832 - val_loss: -0.7058 - val_dice_coef: 0.7058\n",
      "Epoch 15/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6641 - dice_coef: 0.6641 - val_loss: -0.7030 - val_dice_coef: 0.7030\n",
      "Epoch 16/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6857 - dice_coef: 0.6857 - val_loss: -0.7126 - val_dice_coef: 0.7126\n",
      "Epoch 17/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6992 - dice_coef: 0.6992 - val_loss: -0.7185 - val_dice_coef: 0.7185\n",
      "Epoch 18/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7087 - dice_coef: 0.7087 - val_loss: -0.6258 - val_dice_coef: 0.6258\n",
      "Epoch 19/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.6809 - dice_coef: 0.6809 - val_loss: -0.7250 - val_dice_coef: 0.7250\n",
      "Epoch 20/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7041 - dice_coef: 0.7041 - val_loss: -0.6705 - val_dice_coef: 0.6705\n",
      "Epoch 21/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7107 - dice_coef: 0.7107 - val_loss: -0.7040 - val_dice_coef: 0.7040\n",
      "Epoch 22/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7020 - dice_coef: 0.7020 - val_loss: -0.7327 - val_dice_coef: 0.7327\n",
      "Epoch 23/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7290 - dice_coef: 0.7290 - val_loss: -0.7415 - val_dice_coef: 0.7415\n",
      "Epoch 24/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7222 - dice_coef: 0.7222 - val_loss: -0.7424 - val_dice_coef: 0.7424\n",
      "Epoch 25/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7123 - dice_coef: 0.7123 - val_loss: -0.7428 - val_dice_coef: 0.7428\n",
      "Epoch 26/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7207 - dice_coef: 0.7207 - val_loss: -0.7467 - val_dice_coef: 0.7467\n",
      "Epoch 27/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7359 - dice_coef: 0.7359 - val_loss: -0.7502 - val_dice_coef: 0.7502\n",
      "Epoch 28/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7248 - dice_coef: 0.7248 - val_loss: -0.7371 - val_dice_coef: 0.7371\n",
      "Epoch 29/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7432 - dice_coef: 0.7432 - val_loss: -0.7494 - val_dice_coef: 0.7494\n",
      "Epoch 30/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7476 - dice_coef: 0.7476 - val_loss: -0.7531 - val_dice_coef: 0.7531\n",
      "Epoch 31/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7420 - dice_coef: 0.7420 - val_loss: -0.7504 - val_dice_coef: 0.7504\n",
      "Epoch 32/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7404 - dice_coef: 0.7404 - val_loss: -0.7459 - val_dice_coef: 0.7459\n",
      "Epoch 33/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7565 - dice_coef: 0.7565 - val_loss: -0.7619 - val_dice_coef: 0.7619\n",
      "Epoch 34/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7694 - dice_coef: 0.7694 - val_loss: -0.7662 - val_dice_coef: 0.7662\n",
      "Epoch 35/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7595 - dice_coef: 0.7595 - val_loss: -0.7646 - val_dice_coef: 0.7646\n",
      "Epoch 36/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7471 - dice_coef: 0.7471 - val_loss: -0.7732 - val_dice_coef: 0.7732\n",
      "Epoch 37/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7661 - dice_coef: 0.7661 - val_loss: -0.7750 - val_dice_coef: 0.7750\n",
      "Epoch 38/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7744 - dice_coef: 0.7744 - val_loss: -0.7807 - val_dice_coef: 0.7807\n",
      "Epoch 39/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7791 - dice_coef: 0.7791 - val_loss: -0.7168 - val_dice_coef: 0.7168\n",
      "Epoch 40/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7577 - dice_coef: 0.7577 - val_loss: -0.7786 - val_dice_coef: 0.7786\n",
      "Epoch 41/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7817 - dice_coef: 0.7817 - val_loss: -0.7863 - val_dice_coef: 0.7863\n",
      "Epoch 42/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7862 - dice_coef: 0.7862 - val_loss: -0.7741 - val_dice_coef: 0.7741\n",
      "Epoch 43/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7832 - dice_coef: 0.7832 - val_loss: -0.7852 - val_dice_coef: 0.7852\n",
      "Epoch 44/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7878 - dice_coef: 0.7878 - val_loss: -0.7814 - val_dice_coef: 0.7814\n",
      "Epoch 45/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7903 - dice_coef: 0.7903 - val_loss: -0.7917 - val_dice_coef: 0.7917\n",
      "Epoch 46/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7882 - dice_coef: 0.7882 - val_loss: -0.7798 - val_dice_coef: 0.7798\n",
      "Epoch 47/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7722 - dice_coef: 0.7722 - val_loss: -0.7844 - val_dice_coef: 0.7844\n",
      "Epoch 48/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7894 - dice_coef: 0.7894 - val_loss: -0.7957 - val_dice_coef: 0.7957\n",
      "Epoch 49/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7793 - dice_coef: 0.7793 - val_loss: -0.7088 - val_dice_coef: 0.7088\n",
      "Epoch 50/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7757 - dice_coef: 0.7757 - val_loss: -0.7608 - val_dice_coef: 0.7608\n",
      "Epoch 51/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7944 - dice_coef: 0.7944 - val_loss: -0.7936 - val_dice_coef: 0.7936\n",
      "Epoch 52/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7951 - dice_coef: 0.7951 - val_loss: -0.7975 - val_dice_coef: 0.7975\n",
      "Epoch 53/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7966 - dice_coef: 0.7966 - val_loss: -0.8022 - val_dice_coef: 0.8022\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8033 - dice_coef: 0.8033 - val_loss: -0.7746 - val_dice_coef: 0.7746\n",
      "Epoch 55/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7975 - dice_coef: 0.7975 - val_loss: -0.7962 - val_dice_coef: 0.7962\n",
      "Epoch 56/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8028 - dice_coef: 0.8028 - val_loss: -0.8064 - val_dice_coef: 0.8064\n",
      "Epoch 57/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7911 - dice_coef: 0.7911 - val_loss: -0.7947 - val_dice_coef: 0.7947\n",
      "Epoch 58/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.7904 - dice_coef: 0.7904 - val_loss: -0.7940 - val_dice_coef: 0.7940\n",
      "Epoch 59/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8047 - dice_coef: 0.8047 - val_loss: -0.7740 - val_dice_coef: 0.7740\n",
      "Epoch 60/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8056 - dice_coef: 0.8056 - val_loss: -0.8023 - val_dice_coef: 0.8023\n",
      "Epoch 61/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8047 - dice_coef: 0.8047 - val_loss: -0.8097 - val_dice_coef: 0.8097\n",
      "Epoch 62/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8088 - dice_coef: 0.8088 - val_loss: -0.8026 - val_dice_coef: 0.8026\n",
      "Epoch 63/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8090 - dice_coef: 0.8090 - val_loss: -0.8122 - val_dice_coef: 0.8122\n",
      "Epoch 64/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8108 - dice_coef: 0.8108 - val_loss: -0.7903 - val_dice_coef: 0.7903\n",
      "Epoch 65/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8038 - dice_coef: 0.8038 - val_loss: -0.7962 - val_dice_coef: 0.7962\n",
      "Epoch 66/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.8040 - val_dice_coef: 0.8040\n",
      "Epoch 67/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8156 - dice_coef: 0.8156 - val_loss: -0.8156 - val_dice_coef: 0.8156\n",
      "Epoch 68/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8130 - dice_coef: 0.8130 - val_loss: -0.7798 - val_dice_coef: 0.7798\n",
      "Epoch 69/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8040 - dice_coef: 0.8040 - val_loss: -0.8160 - val_dice_coef: 0.8160\n",
      "Epoch 70/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8147 - dice_coef: 0.8147 - val_loss: -0.8083 - val_dice_coef: 0.8083\n",
      "Epoch 71/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8141 - dice_coef: 0.8141 - val_loss: -0.8104 - val_dice_coef: 0.8104\n",
      "Epoch 72/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8245 - dice_coef: 0.8245 - val_loss: -0.8030 - val_dice_coef: 0.8030\n",
      "Epoch 73/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8223 - dice_coef: 0.8223 - val_loss: -0.8112 - val_dice_coef: 0.8112\n",
      "Epoch 74/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8195 - dice_coef: 0.8195 - val_loss: -0.8225 - val_dice_coef: 0.8225\n",
      "Epoch 75/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8159 - dice_coef: 0.8159 - val_loss: -0.8193 - val_dice_coef: 0.8193\n",
      "Epoch 76/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8232 - dice_coef: 0.8232 - val_loss: -0.8235 - val_dice_coef: 0.8235\n",
      "Epoch 77/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8287 - dice_coef: 0.8287 - val_loss: -0.8220 - val_dice_coef: 0.8220\n",
      "Epoch 78/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8222 - dice_coef: 0.8222 - val_loss: -0.8179 - val_dice_coef: 0.8179\n",
      "Epoch 79/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8299 - dice_coef: 0.8299 - val_loss: -0.8256 - val_dice_coef: 0.8256\n",
      "Epoch 80/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8273 - dice_coef: 0.8273 - val_loss: -0.8204 - val_dice_coef: 0.8204\n",
      "Epoch 81/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8249 - dice_coef: 0.8249 - val_loss: -0.8267 - val_dice_coef: 0.8267\n",
      "Epoch 82/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8266 - dice_coef: 0.8266 - val_loss: -0.8168 - val_dice_coef: 0.8168\n",
      "Epoch 83/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8271 - dice_coef: 0.8271 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 84/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8310 - dice_coef: 0.8310 - val_loss: -0.8281 - val_dice_coef: 0.8281\n",
      "Epoch 85/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8165 - dice_coef: 0.8165 - val_loss: -0.8298 - val_dice_coef: 0.8298\n",
      "Epoch 86/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8257 - dice_coef: 0.8257 - val_loss: -0.8202 - val_dice_coef: 0.8202\n",
      "Epoch 87/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8322 - dice_coef: 0.8322 - val_loss: -0.7719 - val_dice_coef: 0.7719\n",
      "Epoch 88/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8311 - dice_coef: 0.8311 - val_loss: -0.7976 - val_dice_coef: 0.7976\n",
      "Epoch 89/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8297 - dice_coef: 0.8297 - val_loss: -0.7369 - val_dice_coef: 0.7369\n",
      "Epoch 90/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8306 - dice_coef: 0.8306 - val_loss: -0.8238 - val_dice_coef: 0.8238\n",
      "Epoch 91/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8364 - dice_coef: 0.8364 - val_loss: -0.8105 - val_dice_coef: 0.8105\n",
      "Epoch 92/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8335 - dice_coef: 0.8335 - val_loss: -0.8325 - val_dice_coef: 0.8325\n",
      "Epoch 93/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8340 - dice_coef: 0.8340 - val_loss: -0.8331 - val_dice_coef: 0.8331\n",
      "Epoch 94/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8258 - dice_coef: 0.8258 - val_loss: -0.8304 - val_dice_coef: 0.8304\n",
      "Epoch 95/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8372 - dice_coef: 0.8372 - val_loss: -0.8016 - val_dice_coef: 0.8016\n",
      "Epoch 96/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8338 - dice_coef: 0.8338 - val_loss: -0.8038 - val_dice_coef: 0.8038\n",
      "Epoch 97/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.8291 - val_dice_coef: 0.8291\n",
      "Epoch 98/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8352 - dice_coef: 0.8352 - val_loss: -0.8341 - val_dice_coef: 0.8341\n",
      "Epoch 99/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8406 - dice_coef: 0.8406 - val_loss: -0.8367 - val_dice_coef: 0.8367\n",
      "Epoch 100/100\n",
      "1452/1452 [==============================] - 49s 34ms/step - loss: -0.8408 - dice_coef: 0.8408 - val_loss: -0.7897 - val_dice_coef: 0.7897\n"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    history = model.fit(X_train, Y_train, batch_size=32, epochs=100, verbose=1,\n",
    "                  shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
