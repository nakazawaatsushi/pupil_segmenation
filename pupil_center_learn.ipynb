{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Flatten, Dense, Dropout\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray\n",
    "from create_fcn import create_fcn01, create_pupil_net00\n",
    "from fname_func import load_fnames, make_fnames\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_center(im):\n",
    "    im[im>0] = 1;\n",
    "    xval = 0\n",
    "    yval = 0\n",
    "    npix = 0\n",
    "\n",
    "    for x in range(0,im.shape[1]):\n",
    "        xval += (x*sum(im[:,x]))\n",
    "        npix += sum(im[:,x])\n",
    "    \n",
    "    for y in range(0,im.shape[0]):\n",
    "        yval += (y*sum(im[y,:]))\n",
    "    \n",
    "    return [xval/npix,yval/npix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  MAIN STARTS FROM HERE\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints_pupil_net00.augumented.woInitialize'\n",
    "    dname_checkpoints_fcn01 = 'checkpoints_fcn01'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    fname_history = \"history.pkl\"\n",
    "\n",
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model_pupil_net = create_pupil_net00(target_size)\n",
    "    \n",
    "    if os.path.exists(dname_checkpoints) == 0:\n",
    "        os.mkdir(dname_checkpoints)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading validation data\n",
      "==> 7800 training images loaded\n",
      "==> 7800 training masks loaded\n",
      "==> 1196 validation images loaded\n",
      "==> 1196 validation masks loaded\n",
      "computing mean and standard deviation...\n",
      "==> mean: [125.60018   90.205666  77.57043 ]\n",
      "==> std : [61.01421  47.890713 51.63054 ]\n",
      "saving mean and standard deviation to stats01.npz...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   LEARNING MODE\n",
    "#\n",
    "    # Read Learning Data\n",
    "    fnames = load_fnames('data_augumented/list_train_01.txt')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data_augumented/img','data_augumented/mask','')\n",
    "\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) \n",
    "\n",
    "    # Read Validation Data\n",
    "    fnames = load_fnames('data_augumented/list_valid_01.txt')\n",
    "    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data_augumented/img','data_augumented/mask','')\n",
    "    \n",
    "    print('reading validation data')\n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)      \n",
    "\n",
    "    # obtain center of pupil\n",
    "    center_train = []\n",
    "    center_valid = []\n",
    "    \n",
    "    for i in range(Y_train.shape[0]):\n",
    "        center_train.append(get_center(Y_train[i,0,:,:]))\n",
    "\n",
    "    for i in range(Y_valid.shape[0]):\n",
    "        center_valid.append(get_center(Y_valid[i,0,:,:]))\n",
    "    \n",
    "    center_train = np.array(center_train)\n",
    "    center_valid = np.array(center_valid)\n",
    "\n",
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')\n",
    "\n",
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    if os.path.exists(dname_checkpoints) == 0:\n",
    "        os.mkdir(dname_checkpoints)\n",
    "    np.savez(dname_checkpoints + '/' + fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fcn00_initialization = 0\n",
    "    \n",
    "    if fcn00_initialization == 1:\n",
    "        # モデルに学習済のfcn01 Weightをロードする\n",
    "        epoch = 100\n",
    "        fname_weights = 'model_weights_%02d.h5'%(epoch)\n",
    "        model_fcn01 = create_fcn01(target_size)\n",
    "        fpath_weights_fcn01 = os.path.join(dname_checkpoints_fcn01, fname_weights)\n",
    "        model_fcn01.load_weights(fpath_weights_fcn01)\n",
    "\n",
    "        # load weights from Learned U-NET\n",
    "        layer_names = ['conv1_1','conv1_2','conv2_1','conv2_2']\n",
    "\n",
    "        print('copying layer weights')\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            model_pupil_net.get_layer(name).set_weights(model_fcn01.get_layer(name).get_weights())\n",
    "            model_pupil_net.get_layer(name).trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    model_pupil_net.compile(optimizer=adam, loss='mean_squared_error')\n",
    "\n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 7800 samples, validate on 1196 samples\n",
      "Epoch 1/100\n",
      "7800/7800 [==============================] - 117s 15ms/step - loss: 3643.0056 - val_loss: 602.7809\n",
      "Epoch 2/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 508.3908 - val_loss: 424.6449\n",
      "Epoch 3/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 373.7475 - val_loss: 301.9320\n",
      "Epoch 4/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 255.7386 - val_loss: 189.8097\n",
      "Epoch 5/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 158.6129 - val_loss: 126.9787\n",
      "Epoch 6/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 109.9097 - val_loss: 94.9327\n",
      "Epoch 7/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 86.5821 - val_loss: 78.3994\n",
      "Epoch 8/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 72.1080 - val_loss: 66.3613\n",
      "Epoch 9/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 65.1883 - val_loss: 77.2461\n",
      "Epoch 10/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 60.5832 - val_loss: 57.5475\n",
      "Epoch 11/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 54.8187 - val_loss: 60.3826\n",
      "Epoch 12/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 51.5762 - val_loss: 47.7177\n",
      "Epoch 13/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 48.3058 - val_loss: 46.7088\n",
      "Epoch 14/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 46.7649 - val_loss: 42.5266\n",
      "Epoch 15/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 45.2289 - val_loss: 41.9582\n",
      "Epoch 16/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 43.8971 - val_loss: 41.4747\n",
      "Epoch 17/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 41.7390 - val_loss: 38.2294\n",
      "Epoch 18/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 42.7135 - val_loss: 40.9430\n",
      "Epoch 19/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 40.3501 - val_loss: 43.1294\n",
      "Epoch 20/100\n",
      "7800/7800 [==============================] - 103s 13ms/step - loss: 37.7829 - val_loss: 41.5420\n",
      "Epoch 21/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 38.3517 - val_loss: 33.9869\n",
      "Epoch 22/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 36.8369 - val_loss: 34.3998\n",
      "Epoch 23/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 34.6245 - val_loss: 31.7994\n",
      "Epoch 24/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 34.8270 - val_loss: 36.0402\n",
      "Epoch 25/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 33.5678 - val_loss: 31.7517\n",
      "Epoch 26/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 31.5554 - val_loss: 38.3684\n",
      "Epoch 27/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 30.9876 - val_loss: 27.7746\n",
      "Epoch 28/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 31.3949 - val_loss: 28.6339\n",
      "Epoch 29/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 29.3364 - val_loss: 33.4363\n",
      "Epoch 30/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 28.4832 - val_loss: 27.6667\n",
      "Epoch 31/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 28.3263 - val_loss: 34.8448\n",
      "Epoch 32/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 26.8877 - val_loss: 24.7467\n",
      "Epoch 33/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 25.8401 - val_loss: 26.8235\n",
      "Epoch 34/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 25.5473 - val_loss: 25.3583\n",
      "Epoch 35/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 25.0696 - val_loss: 24.7834\n",
      "Epoch 36/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 23.6369 - val_loss: 24.3470\n",
      "Epoch 37/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 24.3785 - val_loss: 26.4894\n",
      "Epoch 38/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 23.3885 - val_loss: 28.3343\n",
      "Epoch 39/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 23.0231 - val_loss: 22.0119\n",
      "Epoch 40/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 22.7630 - val_loss: 22.2675\n",
      "Epoch 41/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 20.6557 - val_loss: 22.4357\n",
      "Epoch 42/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 20.4476 - val_loss: 23.4957\n",
      "Epoch 43/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 22.2242 - val_loss: 21.7111\n",
      "Epoch 44/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 21.1874 - val_loss: 32.2618\n",
      "Epoch 45/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 19.6237 - val_loss: 21.1049\n",
      "Epoch 46/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 18.9514 - val_loss: 21.8050\n",
      "Epoch 47/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 18.6129 - val_loss: 27.4504\n",
      "Epoch 48/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 20.0273 - val_loss: 21.3454\n",
      "Epoch 49/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 17.6115 - val_loss: 20.3350\n",
      "Epoch 50/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 17.3626 - val_loss: 20.3825\n",
      "Epoch 51/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 16.4463 - val_loss: 19.1043\n",
      "Epoch 52/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 16.8452 - val_loss: 19.5503\n",
      "Epoch 53/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 16.2453 - val_loss: 22.3227\n",
      "Epoch 54/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 16.3641 - val_loss: 18.1499\n",
      "Epoch 55/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 15.7727 - val_loss: 17.4549\n",
      "Epoch 56/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 15.1264 - val_loss: 17.6886\n",
      "Epoch 57/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 16.7723 - val_loss: 24.7443\n",
      "Epoch 58/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 14.4726 - val_loss: 17.4197\n",
      "Epoch 59/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 13.9958 - val_loss: 19.7908\n",
      "Epoch 60/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 14.9484 - val_loss: 17.1591\n",
      "Epoch 61/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 14.3136 - val_loss: 17.9704\n",
      "Epoch 62/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 12.8854 - val_loss: 20.8022\n",
      "Epoch 63/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 13.5248 - val_loss: 17.6839\n",
      "Epoch 64/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 12.6049 - val_loss: 19.5151\n",
      "Epoch 65/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 12.8257 - val_loss: 17.0696\n",
      "Epoch 66/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 13.9375 - val_loss: 19.1515\n",
      "Epoch 67/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 12.5414 - val_loss: 16.3658\n",
      "Epoch 68/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 11.7384 - val_loss: 17.3447\n",
      "Epoch 69/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 11.9769 - val_loss: 16.8165\n",
      "Epoch 70/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 12.3410 - val_loss: 16.2068\n",
      "Epoch 71/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 11.3773 - val_loss: 14.7295\n",
      "Epoch 72/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 11.0972 - val_loss: 16.7123\n",
      "Epoch 73/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 11.0040 - val_loss: 15.0680\n",
      "Epoch 74/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 10.3389 - val_loss: 14.4620\n",
      "Epoch 75/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 10.2617 - val_loss: 15.3673\n",
      "Epoch 76/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 12.1207 - val_loss: 15.4285\n",
      "Epoch 77/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 10.6027 - val_loss: 13.9622\n",
      "Epoch 78/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 9.9149 - val_loss: 15.4087\n",
      "Epoch 79/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 10.3211 - val_loss: 19.5122\n",
      "Epoch 80/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 10.6461 - val_loss: 14.6181\n",
      "Epoch 81/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 9.6600 - val_loss: 14.1839\n",
      "Epoch 82/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 9.8495 - val_loss: 13.8359\n",
      "Epoch 83/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 9.3696 - val_loss: 14.0904\n",
      "Epoch 84/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 9.2405 - val_loss: 16.1742\n",
      "Epoch 85/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 9.7739 - val_loss: 14.1207\n",
      "Epoch 86/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.7269 - val_loss: 14.3848\n",
      "Epoch 87/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.5352 - val_loss: 13.8017\n",
      "Epoch 88/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.7013 - val_loss: 13.2604\n",
      "Epoch 89/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.3250 - val_loss: 14.7357\n",
      "Epoch 90/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.4113 - val_loss: 16.5661\n",
      "Epoch 91/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.3746 - val_loss: 13.0433\n",
      "Epoch 92/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.4919 - val_loss: 15.3193\n",
      "Epoch 93/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.5587 - val_loss: 13.5677\n",
      "Epoch 94/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.1156 - val_loss: 15.3975\n",
      "Epoch 95/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.0068 - val_loss: 12.7967\n",
      "Epoch 96/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 7.9149 - val_loss: 12.1344\n",
      "Epoch 97/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 7.2663 - val_loss: 13.5990\n",
      "Epoch 98/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 7.2068 - val_loss: 16.2977\n",
      "Epoch 99/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 8.3604 - val_loss: 12.0820\n",
      "Epoch 100/100\n",
      "7800/7800 [==============================] - 102s 13ms/step - loss: 7.4404 - val_loss: 16.5009\n"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    history = model_pupil_net.fit(X_train, center_train, batch_size=64, epochs=200, verbose=1,\n",
    "                  shuffle=True, validation_data=(X_valid, center_valid), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Save History\n",
    "    f = open(dname_checkpoints + '/' + fname_history,'wb')\n",
    "    pickle.dump(history.history,f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#   Show History\n",
    "#\n",
    "    # load pickle\n",
    "    print(dname_checkpoints + '/' + fname_history)\n",
    "    history = pickle.load(open(dname_checkpoints + '/' + fname_history, 'rb'))\n",
    "    \n",
    "    for k in history.keys():\n",
    "        plt.plot(history[k])\n",
    "        plt.title(k)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
