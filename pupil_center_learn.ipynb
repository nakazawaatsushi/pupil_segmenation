{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Flatten, Dense, Dropout\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray\n",
    "from create_fcn import create_fcn01, create_pupil_net00\n",
    "from fname_func import load_fnames, make_fnames\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_center(im):\n",
    "    im[im>0] = 1;\n",
    "    xval = 0\n",
    "    yval = 0\n",
    "    npix = 0\n",
    "\n",
    "    for x in range(0,im.shape[1]):\n",
    "        xval += (x*sum(im[:,x]))\n",
    "        npix += sum(im[:,x])\n",
    "    \n",
    "    for y in range(0,im.shape[0]):\n",
    "        yval += (y*sum(im[y,:]))\n",
    "    \n",
    "    return [xval/npix,yval/npix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  MAIN STARTS FROM HERE\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints_pupil_net00'\n",
    "    dname_checkpoints_fcn01 = 'checkpoints_fcn01'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    fname_history = \"history.pkl\"\n",
    "\n",
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model_pupil_net = create_pupil_net00(target_size)\n",
    "    \n",
    "    if os.path.exists(dname_checkpoints) == 0:\n",
    "        os.mkdir(dname_checkpoints)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading validation data\n",
      "==> 1452 training images loaded\n",
      "==> 1452 training masks loaded\n",
      "==> 527 validation images loaded\n",
      "==> 527 validation masks loaded\n",
      "computing mean and standard deviation...\n",
      "==> mean: [130.65465  91.2685   76.63643]\n",
      "==> std : [55.2817   43.990963 43.113483]\n",
      "saving mean and standard deviation to stats01.npz...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # Read Learning Data\n",
    "    #fnames = load_fnames('data_augumented/list_train_01.txt')\n",
    "    #[fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data_augumented/img','data_augumented/mask','')\n",
    "    fnames = load_fnames('data/list_train_01.txt')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) \n",
    "\n",
    "    # Read Validation Data\n",
    "    #fnames = load_fnames('data_augumented/list_valid_01.txt')\n",
    "    #[fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data_augumented/img','data_augumented/mask','')\n",
    "    fnames = load_fnames('data/list_valid_01.txt')\n",
    "    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    \n",
    "    print('reading validation data')\n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)      \n",
    "\n",
    "    # obtain center of pupil\n",
    "    center_train = []\n",
    "    center_valid = []\n",
    "    \n",
    "    for i in range(Y_train.shape[0]):\n",
    "        center_train.append(get_center(Y_train[i,0,:,:]))\n",
    "\n",
    "    for i in range(Y_valid.shape[0]):\n",
    "        center_valid.append(get_center(Y_valid[i,0,:,:]))\n",
    "    \n",
    "    center_train = np.array(center_train)\n",
    "    center_valid = np.array(center_valid)\n",
    "\n",
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')\n",
    "\n",
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    if os.path.exists(dname_checkpoints) == 0:\n",
    "        os.mkdir(dname_checkpoints)\n",
    "    np.savez(dname_checkpoints + '/' + fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    fcn00_initialization = 0\n",
    "    \n",
    "    if fcn00_initialization == 1:\n",
    "        # モデルに学習済のfcn01 Weightをロードする\n",
    "        epoch = 100\n",
    "        fname_weights = 'model_weights_%02d.h5'%(epoch)\n",
    "        model_fcn01 = create_fcn01(target_size)\n",
    "        fpath_weights_fcn01 = os.path.join(dname_checkpoints_fcn01, fname_weights)\n",
    "        model_fcn01.load_weights(fpath_weights_fcn01)\n",
    "\n",
    "        # load weights from Learned U-NET\n",
    "        layer_names = ['conv1_1','conv1_2','conv2_1','conv2_2']\n",
    "\n",
    "        print('copying layer weights')\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            model_pupil_net.get_layer(name).set_weights(model_fcn01.get_layer(name).get_weights())\n",
    "            model_pupil_net.get_layer(name).trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    model_pupil_net.compile(optimizer=adam, loss='mean_squared_error')\n",
    "\n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 1452 samples, validate on 527 samples\n",
      "Epoch 1/200\n",
      "1452/1452 [==============================] - 38s 26ms/step - loss: 10921.7720 - val_loss: 9105.2632\n",
      "Epoch 2/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 4464.9245 - val_loss: 878.6350\n",
      "Epoch 3/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 498.5362 - val_loss: 339.9911\n",
      "Epoch 4/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 368.0961 - val_loss: 265.8019\n",
      "Epoch 5/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 336.8301 - val_loss: 256.2668\n",
      "Epoch 6/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 327.6134 - val_loss: 247.2496\n",
      "Epoch 7/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 317.6262 - val_loss: 240.3507\n",
      "Epoch 8/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 305.7073 - val_loss: 234.9944\n",
      "Epoch 9/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 292.2700 - val_loss: 231.1805\n",
      "Epoch 10/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 282.0686 - val_loss: 213.2701\n",
      "Epoch 11/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 264.0726 - val_loss: 201.0222\n",
      "Epoch 12/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 253.2389 - val_loss: 190.3288\n",
      "Epoch 13/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 234.2243 - val_loss: 185.2326\n",
      "Epoch 14/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 221.6695 - val_loss: 175.7446\n",
      "Epoch 15/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 204.2107 - val_loss: 163.5187\n",
      "Epoch 16/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 187.7417 - val_loss: 148.1412\n",
      "Epoch 17/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 171.4367 - val_loss: 138.7363\n",
      "Epoch 18/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 158.1984 - val_loss: 125.9674\n",
      "Epoch 19/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 142.6489 - val_loss: 118.5596\n",
      "Epoch 20/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 129.3759 - val_loss: 107.1061\n",
      "Epoch 21/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 125.2222 - val_loss: 117.4844\n",
      "Epoch 22/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 112.4413 - val_loss: 96.8907\n",
      "Epoch 23/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 102.5062 - val_loss: 99.8287\n",
      "Epoch 24/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 96.4363 - val_loss: 89.0531\n",
      "Epoch 25/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 91.3553 - val_loss: 93.0665\n",
      "Epoch 26/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 92.8188 - val_loss: 80.2978\n",
      "Epoch 27/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 87.6777 - val_loss: 79.1684\n",
      "Epoch 28/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 84.2473 - val_loss: 76.4134\n",
      "Epoch 29/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 82.8425 - val_loss: 73.8916\n",
      "Epoch 30/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 79.1868 - val_loss: 71.9195\n",
      "Epoch 31/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 78.8810 - val_loss: 70.4460\n",
      "Epoch 32/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 77.4236 - val_loss: 71.8225\n",
      "Epoch 33/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 79.8273 - val_loss: 69.3934\n",
      "Epoch 34/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 71.3657 - val_loss: 75.1509\n",
      "Epoch 35/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 71.4576 - val_loss: 65.7156\n",
      "Epoch 36/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 67.0840 - val_loss: 69.1128\n",
      "Epoch 37/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 66.0684 - val_loss: 64.3582\n",
      "Epoch 38/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 62.8456 - val_loss: 63.7693\n",
      "Epoch 39/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 62.7528 - val_loss: 68.3356\n",
      "Epoch 40/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 60.9339 - val_loss: 58.0341\n",
      "Epoch 41/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 60.4574 - val_loss: 63.7598\n",
      "Epoch 42/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 58.7857 - val_loss: 55.6330\n",
      "Epoch 43/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 58.0484 - val_loss: 55.0378\n",
      "Epoch 44/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 57.8296 - val_loss: 53.7770\n",
      "Epoch 45/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 58.0014 - val_loss: 52.7094\n",
      "Epoch 46/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 53.2085 - val_loss: 51.5697\n",
      "Epoch 47/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 56.0205 - val_loss: 64.2320\n",
      "Epoch 48/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 57.1421 - val_loss: 50.9406\n",
      "Epoch 49/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 55.1566 - val_loss: 53.7045\n",
      "Epoch 50/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 51.8596 - val_loss: 49.9414\n",
      "Epoch 51/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 47.9193 - val_loss: 50.3537\n",
      "Epoch 52/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 48.7959 - val_loss: 47.4379\n",
      "Epoch 53/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 50.7689 - val_loss: 62.2404\n",
      "Epoch 54/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 57.6323 - val_loss: 50.2317\n",
      "Epoch 55/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 46.5380 - val_loss: 51.2576\n",
      "Epoch 56/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 46.2412 - val_loss: 44.5999\n",
      "Epoch 57/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 45.3111 - val_loss: 47.9246\n",
      "Epoch 58/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 43.3759 - val_loss: 43.7295\n",
      "Epoch 59/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 43.0635 - val_loss: 42.6224\n",
      "Epoch 60/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 43.7694 - val_loss: 43.6362\n",
      "Epoch 61/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 42.8474 - val_loss: 49.0742\n",
      "Epoch 62/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 43.8292 - val_loss: 47.4601\n",
      "Epoch 63/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 44.2608 - val_loss: 45.4640\n",
      "Epoch 64/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 41.0947 - val_loss: 41.1914\n",
      "Epoch 65/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 39.4118 - val_loss: 42.8885\n",
      "Epoch 66/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 42.1105 - val_loss: 57.7487\n",
      "Epoch 67/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 47.4695 - val_loss: 43.7281\n",
      "Epoch 68/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 47.4992 - val_loss: 54.0955\n",
      "Epoch 69/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 39.5591 - val_loss: 38.4602\n",
      "Epoch 70/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 36.2384 - val_loss: 38.4547\n",
      "Epoch 71/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 36.2942 - val_loss: 36.6109\n",
      "Epoch 72/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 35.9569 - val_loss: 35.9182\n",
      "Epoch 73/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 35.2960 - val_loss: 36.2246\n",
      "Epoch 74/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 36.2958 - val_loss: 37.9561\n",
      "Epoch 75/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 35.7748 - val_loss: 42.6701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 35.7694 - val_loss: 37.7605\n",
      "Epoch 77/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 34.1585 - val_loss: 36.3865\n",
      "Epoch 78/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 34.5673 - val_loss: 33.7975\n",
      "Epoch 79/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 32.7844 - val_loss: 32.9784\n",
      "Epoch 80/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 31.8364 - val_loss: 33.0498\n",
      "Epoch 81/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 31.1810 - val_loss: 37.5716\n",
      "Epoch 82/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 36.8262 - val_loss: 37.1160\n",
      "Epoch 83/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 34.1243 - val_loss: 32.2528\n",
      "Epoch 84/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 30.5803 - val_loss: 39.3659\n",
      "Epoch 85/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 32.9522 - val_loss: 31.3210\n",
      "Epoch 86/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 31.3673 - val_loss: 30.8431\n",
      "Epoch 87/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 29.0332 - val_loss: 34.2634\n",
      "Epoch 88/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 33.1508 - val_loss: 34.3034\n",
      "Epoch 89/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 31.8114 - val_loss: 32.3605\n",
      "Epoch 90/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 29.6430 - val_loss: 30.9458\n",
      "Epoch 91/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 28.8773 - val_loss: 29.1761\n",
      "Epoch 92/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 29.2676 - val_loss: 29.8115\n",
      "Epoch 93/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 27.2352 - val_loss: 31.3975\n",
      "Epoch 94/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 28.1600 - val_loss: 28.2753\n",
      "Epoch 95/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 30.2233 - val_loss: 30.5923\n",
      "Epoch 96/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 28.4260 - val_loss: 29.1749\n",
      "Epoch 97/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 27.3502 - val_loss: 29.1562\n",
      "Epoch 98/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 26.0924 - val_loss: 27.6690\n",
      "Epoch 99/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 27.5980 - val_loss: 27.9452\n",
      "Epoch 100/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 25.4937 - val_loss: 26.9518\n",
      "Epoch 101/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 25.0946 - val_loss: 26.1350\n",
      "Epoch 102/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 24.5658 - val_loss: 26.7316\n",
      "Epoch 103/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 24.3784 - val_loss: 25.9428\n",
      "Epoch 104/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 24.9697 - val_loss: 27.6916\n",
      "Epoch 105/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.6605 - val_loss: 26.9799\n",
      "Epoch 106/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.8424 - val_loss: 26.5006\n",
      "Epoch 107/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.6878 - val_loss: 30.8993\n",
      "Epoch 108/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 24.0235 - val_loss: 24.2115\n",
      "Epoch 109/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.7449 - val_loss: 26.8642\n",
      "Epoch 110/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 24.1864 - val_loss: 25.2422\n",
      "Epoch 111/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.6516 - val_loss: 23.4911\n",
      "Epoch 112/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 25.2085 - val_loss: 23.5609\n",
      "Epoch 113/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 23.6019 - val_loss: 30.8242\n",
      "Epoch 114/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.7317 - val_loss: 24.4043\n",
      "Epoch 115/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 21.4605 - val_loss: 23.5998\n",
      "Epoch 116/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 21.7218 - val_loss: 25.8463\n",
      "Epoch 117/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 29.4179 - val_loss: 28.9359\n",
      "Epoch 118/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 26.4281 - val_loss: 23.3935\n",
      "Epoch 119/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 22.8574 - val_loss: 25.7257\n",
      "Epoch 120/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 21.3574 - val_loss: 22.4157\n",
      "Epoch 121/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 20.3817 - val_loss: 22.0512\n",
      "Epoch 122/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.3224 - val_loss: 22.6996\n",
      "Epoch 123/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.8282 - val_loss: 28.6754\n",
      "Epoch 124/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 23.7489 - val_loss: 23.6979\n",
      "Epoch 125/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.9157 - val_loss: 22.1425\n",
      "Epoch 126/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.6334 - val_loss: 22.6802\n",
      "Epoch 127/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.3053 - val_loss: 21.2486\n",
      "Epoch 128/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.3724 - val_loss: 27.1186\n",
      "Epoch 129/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.4415 - val_loss: 20.6340\n",
      "Epoch 130/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.4704 - val_loss: 20.3905\n",
      "Epoch 131/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.7513 - val_loss: 20.6352\n",
      "Epoch 132/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.3206 - val_loss: 20.3927\n",
      "Epoch 133/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.3187 - val_loss: 20.1742\n",
      "Epoch 134/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 18.5986 - val_loss: 22.8850\n",
      "Epoch 135/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 18.4996 - val_loss: 19.9917\n",
      "Epoch 136/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.1570 - val_loss: 19.7847\n",
      "Epoch 137/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 18.9308 - val_loss: 21.1031\n",
      "Epoch 138/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 18.1762 - val_loss: 20.7523\n",
      "Epoch 139/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 21.7271 - val_loss: 27.1931\n",
      "Epoch 140/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 20.0107 - val_loss: 19.5642\n",
      "Epoch 141/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.5958 - val_loss: 39.5927\n",
      "Epoch 142/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 26.8605 - val_loss: 30.5392\n",
      "Epoch 143/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 21.5995 - val_loss: 23.9605\n",
      "Epoch 144/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 19.1903 - val_loss: 19.8479\n",
      "Epoch 145/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 16.9387 - val_loss: 20.5996\n",
      "Epoch 146/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 17.9066 - val_loss: 19.1306\n",
      "Epoch 147/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 17.3532 - val_loss: 21.0167\n",
      "Epoch 148/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 18.6865 - val_loss: 19.0626\n",
      "Epoch 149/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 17.1889 - val_loss: 20.8846\n",
      "Epoch 150/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.9289 - val_loss: 20.1725\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.6153 - val_loss: 19.3763\n",
      "Epoch 152/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.1850 - val_loss: 18.5362\n",
      "Epoch 153/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.9617 - val_loss: 18.5728\n",
      "Epoch 154/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.8235 - val_loss: 19.1393\n",
      "Epoch 155/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 16.8332 - val_loss: 19.7579\n",
      "Epoch 156/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.1473 - val_loss: 19.2892\n",
      "Epoch 157/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.3593 - val_loss: 17.7756\n",
      "Epoch 158/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.6785 - val_loss: 17.8090\n",
      "Epoch 159/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.4649 - val_loss: 18.0066\n",
      "Epoch 160/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.2477 - val_loss: 20.9442\n",
      "Epoch 161/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.3314 - val_loss: 17.3924\n",
      "Epoch 162/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.6812 - val_loss: 18.3420\n",
      "Epoch 163/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 15.2500 - val_loss: 24.0744\n",
      "Epoch 164/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.2679 - val_loss: 20.1507\n",
      "Epoch 165/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.4893 - val_loss: 18.0900\n",
      "Epoch 166/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 16.4389 - val_loss: 19.6713\n",
      "Epoch 167/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.4924 - val_loss: 21.1177\n",
      "Epoch 168/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 18.0481 - val_loss: 23.6355\n",
      "Epoch 169/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.5355 - val_loss: 21.9241\n",
      "Epoch 170/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 15.3823 - val_loss: 17.6379\n",
      "Epoch 171/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.4251 - val_loss: 17.1818\n",
      "Epoch 172/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.6391 - val_loss: 16.8619\n",
      "Epoch 173/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.5822 - val_loss: 22.1595\n",
      "Epoch 174/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.1955 - val_loss: 16.4642\n",
      "Epoch 175/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.7126 - val_loss: 16.9492\n",
      "Epoch 176/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.1902 - val_loss: 17.4254\n",
      "Epoch 177/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 14.5589 - val_loss: 19.6576\n",
      "Epoch 178/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.8548 - val_loss: 17.2548\n",
      "Epoch 179/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.8481 - val_loss: 18.6162\n",
      "Epoch 180/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.9251 - val_loss: 16.4838\n",
      "Epoch 181/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.5035 - val_loss: 16.0107\n",
      "Epoch 182/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.5133 - val_loss: 16.5212\n",
      "Epoch 183/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.6852 - val_loss: 16.9483\n",
      "Epoch 184/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.1582 - val_loss: 16.1096\n",
      "Epoch 185/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.4598 - val_loss: 16.5486\n",
      "Epoch 186/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.6278 - val_loss: 19.4359\n",
      "Epoch 187/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.9086 - val_loss: 17.2579\n",
      "Epoch 188/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 14.9078 - val_loss: 15.9143\n",
      "Epoch 189/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.5220 - val_loss: 17.4904\n",
      "Epoch 190/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.9337 - val_loss: 18.3798\n",
      "Epoch 191/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.3404 - val_loss: 17.2153\n",
      "Epoch 192/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.2156 - val_loss: 15.3840\n",
      "Epoch 193/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.1224 - val_loss: 17.1275\n",
      "Epoch 194/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.6133 - val_loss: 26.1817\n",
      "Epoch 195/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 13.6198 - val_loss: 17.5485\n",
      "Epoch 196/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.4627 - val_loss: 15.8222\n",
      "Epoch 197/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 11.6342 - val_loss: 16.7925\n",
      "Epoch 198/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 12.2011 - val_loss: 18.9630\n",
      "Epoch 199/200\n",
      "1452/1452 [==============================] - 24s 17ms/step - loss: 11.6531 - val_loss: 15.8711\n",
      "Epoch 200/200\n",
      "1452/1452 [==============================] - 25s 17ms/step - loss: 11.2730 - val_loss: 17.2733\n"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    history = model_pupil_net.fit(X_train, center_train, batch_size=64, epochs=200, verbose=1,\n",
    "                  shuffle=True, validation_data=(X_valid, center_valid), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Save History\n",
    "    f = open(dname_checkpoints + '/' + fname_history,'wb')\n",
    "    pickle.dump(history.history,f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_pupil_net00.augumented.woInitialize/history.pkl\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6480b242e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6480b9c8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    #\n",
    "    #   Show History\n",
    "    #\n",
    "    \n",
    "    # load pickle\n",
    "    print(dname_checkpoints + '/' + fname_history)\n",
    "    history = pickle.load(open(dname_checkpoints + '/' + fname_history, 'rb'))\n",
    "    \n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt    \n",
    "    \n",
    "    for k in history.keys():\n",
    "        plt.plot(history[k])\n",
    "        plt.title(k)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
