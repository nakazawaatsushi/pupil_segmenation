{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray, img_dice_coeff\n",
    "from create_fcn import create_fcn02, create_pupil_net\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fnames(paths):\n",
    "    f = open(paths)\n",
    "    data1 = f.read()\n",
    "    f.close()\n",
    "    lines = data1.split('\\n')\n",
    "    #print(len(lines))\n",
    "    # 最終行は空行なので消す\n",
    "    del(lines[len(lines)-1])\n",
    "    #print(len(lines))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fnames(fnames,fpath,fpath_mask,mask_ext):\n",
    "    fnames_img = [];\n",
    "    fnames_mask= [];\n",
    "    \n",
    "    for i in range(len(fnames)):\n",
    "        fnames_img.append(fpath + '/' + fnames[i]);\n",
    "        fnames_mask.append(fpath_mask + '/' + mask_ext + fnames[i]);\n",
    "        \n",
    "    return [fnames_img,fnames_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 224, 224)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                 (None, 32, 224, 224)  896         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv1_2 (Conv2D)                 (None, 32, 224, 224)  9248        conv1_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, 32, 112, 112)  0           conv1_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                 (None, 64, 112, 112)  18496       max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2_2 (Conv2D)                 (None, 64, 112, 112)  36928       conv2_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, 64, 56, 56)    0           conv2_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv3_1 (Conv2D)                 (None, 128, 56, 56)   73856       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv3_2 (Conv2D)                 (None, 128, 56, 56)   147584      conv3_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, 128, 28, 28)   0           conv3_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv4_1 (Conv2D)                 (None, 256, 28, 28)   295168      max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv4_2 (Conv2D)                 (None, 256, 28, 28)   590080      conv4_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)   (None, 256, 56, 56)   0           conv4_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 384, 56, 56)   0           up_sampling2d_1[0][0]            \n",
      "                                                                   conv3_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv5_1 (Conv2D)                 (None, 128, 56, 56)   442496      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv5_2 (Conv2D)                 (None, 128, 56, 56)   147584      conv5_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)   (None, 128, 112, 112) 0           conv5_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 192, 112, 112) 0           up_sampling2d_2[0][0]            \n",
      "                                                                   conv2_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv6_1 (Conv2D)                 (None, 64, 112, 112)  110656      concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv6_2 (Conv2D)                 (None, 64, 112, 112)  36928       conv6_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)   (None, 64, 224, 224)  0           conv6_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 96, 224, 224)  0           up_sampling2d_3[0][0]            \n",
      "                                                                   conv1_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv7_1 (Conv2D)                 (None, 32, 224, 224)  27680       concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv7_2 (Conv2D)                 (None, 32, 224, 224)  9248        conv7_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv8 (Conv2D)                   (None, 1, 224, 224)   33          conv7_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,946,881\n",
      "Trainable params: 1,946,881\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  MAIN STARTS FROM HERE\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints_fcn02'\n",
    "    dname_outputs = 'outputs'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    fname_history = \"history.pkl\"\n",
    "\n",
    "    # definision of mode, LEARN or TEST or SHOW_HISTORY\n",
    "    mode = \"TEST\"\n",
    "\n",
    "    # モデルを作成\n",
    "    print('creating model...')\n",
    "    model = create_fcn02(target_size)\n",
    "    model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-b9246c8023ae>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-b9246c8023ae>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    if mode == \"LEARN\":\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   LEARNING MODE\n",
    "#\n",
    "if mode == \"LEARN\":\n",
    "    # Read Learning Data\n",
    "    fnames = load_fnames('data/list_train_01.txt')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) \n",
    "\n",
    "    # Read Validation Data\n",
    "    fnames = load_fnames('data/list_valid_01.txt')\n",
    "    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "\n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fafee8977b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'==> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' training images loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'==> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' training masks loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'==> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' validation images loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'==> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' validation masks loaded'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing mean and standard deviation...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8cd8c575eb93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 前処理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'computing mean and standard deviation...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'==> mean: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.1, nesterov=True)\n",
    "    #rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "    # モデルの構造を保存\n",
    "    json_string = model.to_json()\n",
    "    fpath_architecture = os.path.join(dpath_checkpoints, fname_architecture)\n",
    "    with open(fpath_architecture, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(json_string)\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-be08c15cbcb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# トレーニングを開始\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'start training...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m history = model.fit(X_train, Y_train, batch_size=32, epochs=100, verbose=1,\n\u001b[0m\u001b[0;32m      4\u001b[0m               shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    history = model.fit(X_train, Y_train, batch_size=32, epochs=100, verbose=1,\n",
    "                  shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-dadc4c67b0f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save History\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdname_checkpoints\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "    # Save History\n",
    "    f = open(dname_checkpoints + '/' + fname_history,'wb')\n",
    "    pickle.dump(history.history,f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> done\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  TEST MODE\n",
    "#\n",
    "if mode == \"TEST\":\n",
    "    # Prediction (test) mode\n",
    "\n",
    "    # 学習済みの重みをロード\n",
    "    epoch = 299\n",
    "    fname_weights = 'model_weights_%02d.h5'%(epoch)\n",
    "    fpath_weights = os.path.join(dname_checkpoints, fname_weights)\n",
    "    model.load_weights(fpath_weights)\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mean and standard deviation from stats01.npz...\n",
      "==> mean: [ 130.65464783   91.26850128   76.63642883]\n",
      "==> std : [ 55.28170013  43.99096298  43.11348343]\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # Read Test Data\n",
    "    fnames = load_fnames('data/list_test_01.txt')\n",
    "\n",
    "    [fpaths_xs_test,fpaths_ys_test] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "\n",
    "    X_test = load_imgs_asarray(fpaths_xs_test, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    #Y_test = load_imgs_asarray(fpaths_ys_test, grayscale=True, target_size=target_size,\n",
    "    #                            dim_ordering=dim_ordering)\n",
    "\n",
    "    # トレーニング時に計算した平均・標準偏差をロード    \n",
    "    print('loading mean and standard deviation from ' + fname_stats + '...')\n",
    "    stats = np.load(fname_stats)\n",
    "    mean = stats['mean']\n",
    "    std = stats['std']\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    for i in range(3):\n",
    "        X_test[:, i] = (X_test[:, i] - mean[i]) / std[i]\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # テストを開始\n",
    "    outputs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving outputs as images...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # 出力を画像として保存\n",
    "    dname_outputs = './outputs/'\n",
    "    if not os.path.isdir(dname_outputs):\n",
    "        print('create directory: %s'%(dname_outputs))\n",
    "        os.mkdir(dname_outputs)\n",
    "\n",
    "    print('saving outputs as images...')\n",
    "    n = 0\n",
    "    for i, array in enumerate(outputs):\n",
    "        array = np.where(array > 0.5, 1, 0) # 二値に変換\n",
    "        array = array.astype(np.float32)\n",
    "        img_out = array_to_img(array, dim_ordering)\n",
    "        # fpath_out = os.path.join(dname_outputs, fnames[i])\n",
    "        fpath_out = os.path.join(dname_outputs, \"%05d.png\"%(n))\n",
    "        img_out.save(fpath_out)\n",
    "        n = n + 1\n",
    "\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000: Dice Coeff = 0.867624\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cd56b9785ba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0moverlap_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim2a\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim3a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%03d: Dice Coeff = %f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverlap_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverlap_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mimg_dice_coeff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mdice_eval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverlap_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moverlap_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\pupil_segmenation\\image_ext.py\u001b[0m in \u001b[0;36mimg_dice_coeff\u001b[1;34m(im1, im2)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimg_dice_coeff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Compute dice coeff\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mim1a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mim1a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mim1a\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mim2a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    n = 0\n",
    "    dice_eval = []\n",
    "    \n",
    "    for i in range(len(fpaths_xs_test)):\n",
    "        # テスト画像\n",
    "        im1 = Image.open(fpaths_xs_test[i])\n",
    "        im1 = im1.resize((320,240)) \n",
    "        # 出力結果\n",
    "        im2 = Image.open(os.path.join(dname_outputs, \"%05d.png\"%(n)))\n",
    "        im2 = im2.resize((320,240))\n",
    "        # Grond Truth\n",
    "        im3 = Image.open(fpaths_ys_test[i])\n",
    "        im3 = im3.resize((320,240))\n",
    "\n",
    "        im2_d = np.zeros((240,320,3), 'uint8')\n",
    "        im2_d[:,:,0] = np.array(im2)\n",
    "        im2_d[:,:,1] = np.array(im3)*255\n",
    "        im2_d[:,:,2] = 0\n",
    "\n",
    "        # Compute dice coeff\n",
    "        im2a = np.array(im2)\n",
    "        im2a[im2a > 0] = 1\n",
    "        im3a = np.array(im3)\n",
    "        im3a[im3a > 0] = 1\n",
    "        \n",
    "        overlap_a = np.array(im2a) * np.array(im3a)\n",
    "        overlap_b = np.array(im2a) + np.array(im3a)\n",
    "        print('%03d: Dice Coeff = %f'%(i, 2*sum(sum(overlap_a))/sum(sum(overlap_b))))\n",
    "        print('%f'%img_dice_coeff(im2,im3))\n",
    "        dice_eval.append(2*sum(sum(overlap_a))/sum(sum(overlap_b)))\n",
    "\n",
    "        plt.imshow(np.hstack((np.array(im1),np.array(im2_d))))\n",
    "        plt.show()\n",
    "\n",
    "        n = n + 1\n",
    "    \n",
    "    print('Dice eval av. : %f'%np.mean(np.array(dice_eval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Show History\n",
    "#\n",
    "mode = \"SHOW_HISTORY\"\n",
    "if mode == \"SHOW_HISTORY\":\n",
    "    # load pickle\n",
    "    print(dname_checkpoints + '/' + fname_history)\n",
    "    history = pickle.load(open(dname_checkpoints + '/' + fname_history, 'rb'))\n",
    "    \n",
    "    for k in history.keys():\n",
    "        plt.plot(history[k])\n",
    "        plt.title(k)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_dice_coef', 'loss', 'dice_coef'])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
