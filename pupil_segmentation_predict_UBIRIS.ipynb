{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "#   LEARN FCN00\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, AveragePooling2D\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray, img_dice_coeff, get_center\n",
    "from fname_func import load_fnames, make_fnames\n",
    "\n",
    "# MAXPOOLING\n",
    "from create_fcn import create_fcn01, create_fcn00\n",
    "# AVERAGE POOLING\n",
    "#from create_fcn_avpool import create_fcn01,create_fcn00\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model fcn00...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  MAIN STARTS FROM HERE\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    argv = sys.argv\n",
    "    argc = len(argv)\n",
    "    if argc < 3:\n",
    "        print('usage: %s [TEST_SEQ] [EPOCH]'%(argv[0]))\n",
    "        sys.exit(0)\n",
    "    \n",
    "    TEST_SEQ = argv[1]\n",
    "    epoch = argv[2]\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints_UBIRIS.augumented.' + TEST_SEQ\n",
    "    #dname_checkpoints = 'checkpoints_fcn00.augumented_2.alldata'\n",
    "    dname_outputs = 'outputs.UBIRIS.augumented.' + TEST_SEQ\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    fname_history = \"history.pkl\"\n",
    "\n",
    "    # モデルを作成\n",
    "    print('creating model fcn00...')\n",
    "    model_fcn00 = create_fcn00(target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mean and standard deviation from stats01.npz...\n",
      "==> mean: [ 126.13108063   90.50558472   78.30973053]\n",
      "==> std : [ 60.96895599  47.60325623  52.20940781]\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    # Test Gi4e data\n",
    "    #\n",
    "    #fnames = load_fnames('data.gi4e/list_test' + argv[1] + '.txt')\n",
    "    fnames = load_fnames('data_augumented/list_test_' + TEST_SEQ + '.txt')\n",
    "    \n",
    "    [fpaths_xs_test,fpaths_ys_test] = make_fnames(fnames,'data_augumented/img','','')\n",
    "    \n",
    "    X_test = load_imgs_asarray(fpaths_xs_test, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    \n",
    "    # トレーニング時に計算した平均・標準偏差をロード    \n",
    "    print('loading mean and standard deviation from ' + fname_stats + '...')\n",
    "    stats = np.load(dname_checkpoints + '/' + fname_stats)\n",
    "    mean = stats['mean']\n",
    "    std = stats['std']\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))\n",
    "\n",
    "    for i in range(3):\n",
    "        X_test[:, i] = (X_test[:, i] - mean[i]) / std[i]\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 学習済みの重みをロー\n",
    "    fname_weights = 'model_weights_%02d.h5'%(int(epoch))\n",
    "    fpath_weights = os.path.join(dname_checkpoints, fname_weights)\n",
    "    model_fcn00.load_weights(fpath_weights)\n",
    "    print('==> done')\n",
    "\n",
    "    # テストを開始\n",
    "    outputs = model_fcn00.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create directory: ./outputs.gi4e-right.learnedbyubiris/\n",
      "saving outputs as images...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    # 出力を画像として保存\n",
    "    if not os.path.isdir(dname_outputs):\n",
    "        print('create directory: %s'%(dname_outputs))\n",
    "        os.mkdir(dname_outputs)\n",
    "\n",
    "    print('saving outputs as images...')\n",
    "    for i, array in enumerate(outputs):\n",
    "        #array = np.where(array > 0.1, 1, 0) # 二値に変換\n",
    "        #array = array.astype(np.float)\n",
    "        formatted = (array[0]*255.0/np.max(array[0])).astype('uint8')\n",
    "        #img_out = array_to_img(array, dim_ordering)\n",
    "        img_out = Image.fromarray(formatted)\n",
    "        fpath_out = os.path.join(dname_outputs, \"%s\"%(fnames[i]))\n",
    "        img_out.save(fpath_out)\n",
    "\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-69385e653f63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mim2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Grond Truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3/lib/python3.5/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "#    dice_eval = []\n",
    "#\n",
    "#    for i in range(len(fpaths_xs_test)):\n",
    "#        # テスト画像\n",
    "#        im1 = Image.open(fpaths_xs_test[i])\n",
    "#        im1 = im1.resize((320,240)) \n",
    "#        # 出力結果\n",
    "#        im2 = Image.open(os.path.join(dname_outputs, \"%s\"%(fnames[i])))\n",
    "#        im2 = im2.resize((320,240))\n",
    "#        # Grond Truth\n",
    "#        plt.imshow(np.hstack((np.array(im1),np.array(im2))))\n",
    "#        plt.show()\n",
    "#    \n",
    "#    print('%d: Dice eval av. : %f'%(epoch,np.mean(np.array(dice_eval))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
