{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "#   LEARN FCN00\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, AveragePooling2D\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray, img_dice_coeff\n",
    "from fname_func import load_fnames, make_fnames\n",
    "\n",
    "# MAXPOOLING\n",
    "from create_fcn import create_fcn01, create_fcn00\n",
    "# AVERAGE POOLING\n",
    "#from create_fcn_avpool import create_fcn01,create_fcn00\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model fcn00...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  MAIN STARTS FROM HERE\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    # dname_checkpoints = 'checkpoints_fcn00_avpool.augumented'\n",
    "    dname_checkpoints = 'checkpoints_fcn00.augumented'\n",
    "    # dname_checkpoints_fcn01 = 'checkpoints_fcn01_avpool'\n",
    "    dname_checkpoints_fcn01 = 'checkpoints_fcn01'\n",
    "    dname_outputs = 'outputs'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    fname_history = \"history.pkl\"\n",
    "\n",
    "    # definision of mode, LEARN or TEST or SHOW_HISTORY\n",
    "    #mode = \"LEARN\"\n",
    "    #mode = \"SHOW_HISTORY\"\n",
    "    #mode = \"TEST\"\n",
    "\n",
    "    # モデルを作成\n",
    "    print('creating model fcn00...')\n",
    "    model_fcn00 = create_fcn00(target_size)\n",
    "    \n",
    "    if os.path.exists(dname_checkpoints) == 0:\n",
    "        os.mkdir(dname_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading training data\n",
      "reading traking gt data\n",
      "reading validation data\n",
      "==> 7800 training images loaded\n",
      "==> 7800 training masks loaded\n",
      "==> 1196 validation images loaded\n",
      "==> 1196 validation masks loaded\n",
      "computing mean and standard deviation...\n",
      "==> mean: [125.60018   90.205666  77.57043 ]\n",
      "==> std : [61.01421  47.890713 51.63054 ]\n"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    #   LEARNING MODE\n",
    "    #\n",
    "    # Read Learning Data\n",
    "    #    fnames = load_fnames('data/list_train_01.txt')\n",
    "    #    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    #    fnames = load_fnames('data.nnlab/list_train_01.txt')\n",
    "    #    fnames = load_fnames('data/list_train_01.txt')\n",
    "    fnames = load_fnames('data_augumented/list_train_01.txt')\n",
    "    #    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data.nnlab/image','data.nnlab/gt','')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data_augumented/img','data_augumented/mask','')\n",
    "\n",
    "    print('reading training data')\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    print('reading traking gt data')\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) \n",
    "\n",
    "    # Read Validation Data\n",
    "    #    fnames = load_fnames('data/list_valid_01.txt')\n",
    "    #    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    fnames = load_fnames('data_augumented/list_valid_01.txt')\n",
    "    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data_augumented/img','data_augumented/mask','')\n",
    "    \n",
    "    print('reading validation data')\n",
    "    X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)     \n",
    "\n",
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')\n",
    "\n",
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving mean and standard deviation to stats01.npz...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(dname_checkpoints + '/' + fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    Y_train /= 255\n",
    "    Y_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying layer weights\n",
      "conv1_1\n",
      "conv1_2\n",
      "conv2_1\n",
      "conv2_2\n",
      "up1_1\n",
      "up1_2\n",
      "up2_1\n",
      "up2_2\n",
      "conv_fin\n"
     ]
    }
   ],
   "source": [
    "    init_from_fcn01 = 1\n",
    "    \n",
    "    if init_from_fcn01 == 1:\n",
    "        # モデルに学習済のfcn01 Weightをロードする\n",
    "        model_fcn01 = create_fcn01(target_size)        \n",
    "        epoch = 100\n",
    "        fname_weights = 'model_weights_%02d.h5'%(epoch)\n",
    "        fpath_weights_fcn01 = os.path.join(dname_checkpoints_fcn01, fname_weights)\n",
    "        model_fcn01.load_weights(fpath_weights_fcn01)\n",
    "        #print('==> done')\n",
    "\n",
    "        # load weights from Learned U-NET\n",
    "        layer_names = ['conv1_1','conv1_2','conv2_1','conv2_2','conv3_1','conv3_2',\n",
    "                       'conv4_1','conv4_2','conv5_1', 'conv5_2',\n",
    "                    'up1_1', 'up1_2', 'up2_1', 'up2_2', 'up3_1', 'up3_2', 'up4_1', \n",
    "                       'up4_2', 'conv_fin']\n",
    "        layer_names = ['conv1_1','conv1_2','conv2_1','conv2_2',\n",
    "                    'up1_1', 'up1_2', 'up2_1', 'up2_2', 'conv_fin']\n",
    "\n",
    "        print('copying layer weights')\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            model_fcn00.get_layer(name).set_weights(model_fcn01.get_layer(name).get_weights())\n",
    "            model_fcn00.get_layer(name).trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "    #rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model_fcn00.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 7800 samples, validate on 1196 samples\n",
      "Epoch 1/200\n",
      "7800/7800 [==============================] - 346s 44ms/step - loss: -0.4823 - dice_coef: 0.4823 - val_loss: -0.7134 - val_dice_coef: 0.7134\n",
      "Epoch 2/200\n",
      "7800/7800 [==============================] - 312s 40ms/step - loss: -0.7230 - dice_coef: 0.7230 - val_loss: -0.7607 - val_dice_coef: 0.7607\n",
      "Epoch 3/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.7573 - dice_coef: 0.7573 - val_loss: -0.7553 - val_dice_coef: 0.7553\n",
      "Epoch 4/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.7759 - dice_coef: 0.7759 - val_loss: -0.7890 - val_dice_coef: 0.7890\n",
      "Epoch 5/200\n",
      "7800/7800 [==============================] - 313s 40ms/step - loss: -0.7910 - dice_coef: 0.7910 - val_loss: -0.8049 - val_dice_coef: 0.8049\n",
      "Epoch 6/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8045 - dice_coef: 0.8045 - val_loss: -0.7635 - val_dice_coef: 0.7635\n",
      "Epoch 7/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8149 - dice_coef: 0.8149 - val_loss: -0.8011 - val_dice_coef: 0.8011\n",
      "Epoch 8/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8217 - dice_coef: 0.8217 - val_loss: -0.8104 - val_dice_coef: 0.8104\n",
      "Epoch 9/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8318 - dice_coef: 0.8318 - val_loss: -0.8082 - val_dice_coef: 0.8082\n",
      "Epoch 10/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8402 - dice_coef: 0.8402 - val_loss: -0.7973 - val_dice_coef: 0.7973\n",
      "Epoch 11/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8409 - dice_coef: 0.8409 - val_loss: -0.8053 - val_dice_coef: 0.8053\n",
      "Epoch 12/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8511 - dice_coef: 0.8511 - val_loss: -0.8172 - val_dice_coef: 0.8172\n",
      "Epoch 13/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8603 - dice_coef: 0.8603 - val_loss: -0.8118 - val_dice_coef: 0.8118\n",
      "Epoch 14/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.8653 - dice_coef: 0.8653 - val_loss: -0.8222 - val_dice_coef: 0.8222\n",
      "Epoch 15/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8691 - dice_coef: 0.8691 - val_loss: -0.8140 - val_dice_coef: 0.8140\n",
      "Epoch 16/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.8778 - dice_coef: 0.8778 - val_loss: -0.8213 - val_dice_coef: 0.8213\n",
      "Epoch 17/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.8790 - dice_coef: 0.8790 - val_loss: -0.8000 - val_dice_coef: 0.8000\n",
      "Epoch 18/200\n",
      "7800/7800 [==============================] - 311s 40ms/step - loss: -0.8832 - dice_coef: 0.8832 - val_loss: -0.7899 - val_dice_coef: 0.7899\n",
      "Epoch 19/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.8891 - dice_coef: 0.8891 - val_loss: -0.8241 - val_dice_coef: 0.8241\n",
      "Epoch 20/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.8954 - dice_coef: 0.8954 - val_loss: -0.8247 - val_dice_coef: 0.8247\n",
      "Epoch 21/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.8162 - val_dice_coef: 0.8162\n",
      "Epoch 22/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9050 - dice_coef: 0.9050 - val_loss: -0.8066 - val_dice_coef: 0.8066\n",
      "Epoch 23/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9082 - dice_coef: 0.9082 - val_loss: -0.8235 - val_dice_coef: 0.8235\n",
      "Epoch 24/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9073 - dice_coef: 0.9073 - val_loss: -0.8078 - val_dice_coef: 0.8078\n",
      "Epoch 25/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9151 - dice_coef: 0.9151 - val_loss: -0.8176 - val_dice_coef: 0.8176\n",
      "Epoch 26/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9213 - dice_coef: 0.9213 - val_loss: -0.8110 - val_dice_coef: 0.8110\n",
      "Epoch 27/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9237 - dice_coef: 0.9237 - val_loss: -0.8195 - val_dice_coef: 0.8195\n",
      "Epoch 28/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9245 - dice_coef: 0.9245 - val_loss: -0.8240 - val_dice_coef: 0.8240\n",
      "Epoch 29/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9306 - dice_coef: 0.9306 - val_loss: -0.8223 - val_dice_coef: 0.8223\n",
      "Epoch 30/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9330 - dice_coef: 0.9330 - val_loss: -0.8165 - val_dice_coef: 0.8165\n",
      "Epoch 31/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9337 - dice_coef: 0.9337 - val_loss: -0.8178 - val_dice_coef: 0.8178\n",
      "Epoch 32/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9337 - dice_coef: 0.9337 - val_loss: -0.8183 - val_dice_coef: 0.8183\n",
      "Epoch 33/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9384 - dice_coef: 0.9384 - val_loss: -0.8151 - val_dice_coef: 0.8151\n",
      "Epoch 34/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9377 - dice_coef: 0.9377 - val_loss: -0.8177 - val_dice_coef: 0.8177\n",
      "Epoch 35/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9400 - dice_coef: 0.9400 - val_loss: -0.8221 - val_dice_coef: 0.8221\n",
      "Epoch 36/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9448 - dice_coef: 0.9448 - val_loss: -0.8182 - val_dice_coef: 0.8182\n",
      "Epoch 37/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9431 - dice_coef: 0.9431 - val_loss: -0.8184 - val_dice_coef: 0.8184\n",
      "Epoch 38/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9469 - dice_coef: 0.9469 - val_loss: -0.8200 - val_dice_coef: 0.8200\n",
      "Epoch 39/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9461 - dice_coef: 0.9461 - val_loss: -0.8136 - val_dice_coef: 0.8136\n",
      "Epoch 40/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9479 - dice_coef: 0.9479 - val_loss: -0.8145 - val_dice_coef: 0.8145\n",
      "Epoch 41/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9502 - dice_coef: 0.9502 - val_loss: -0.8184 - val_dice_coef: 0.8184\n",
      "Epoch 42/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9519 - dice_coef: 0.9519 - val_loss: -0.8123 - val_dice_coef: 0.8123\n",
      "Epoch 43/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9500 - dice_coef: 0.9500 - val_loss: -0.8208 - val_dice_coef: 0.8208\n",
      "Epoch 44/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9486 - dice_coef: 0.9486 - val_loss: -0.8216 - val_dice_coef: 0.8216\n",
      "Epoch 45/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9555 - dice_coef: 0.9555 - val_loss: -0.8174 - val_dice_coef: 0.8174\n",
      "Epoch 46/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9566 - dice_coef: 0.9566 - val_loss: -0.8163 - val_dice_coef: 0.8163\n",
      "Epoch 47/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9530 - dice_coef: 0.9530 - val_loss: -0.8123 - val_dice_coef: 0.8123\n",
      "Epoch 48/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9570 - dice_coef: 0.9570 - val_loss: -0.8187 - val_dice_coef: 0.8187\n",
      "Epoch 49/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9566 - dice_coef: 0.9566 - val_loss: -0.8185 - val_dice_coef: 0.8185\n",
      "Epoch 50/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9585 - dice_coef: 0.9585 - val_loss: -0.8177 - val_dice_coef: 0.8177\n",
      "Epoch 51/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9576 - dice_coef: 0.9576 - val_loss: -0.8101 - val_dice_coef: 0.8101\n",
      "Epoch 52/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9599 - dice_coef: 0.9599 - val_loss: -0.8213 - val_dice_coef: 0.8213\n",
      "Epoch 53/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9602 - dice_coef: 0.9602 - val_loss: -0.8194 - val_dice_coef: 0.8194\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9593 - dice_coef: 0.9593 - val_loss: -0.8178 - val_dice_coef: 0.8178\n",
      "Epoch 55/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9625 - dice_coef: 0.9625 - val_loss: -0.8180 - val_dice_coef: 0.8180\n",
      "Epoch 56/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9603 - dice_coef: 0.9603 - val_loss: -0.8133 - val_dice_coef: 0.8133\n",
      "Epoch 57/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9597 - dice_coef: 0.9597 - val_loss: -0.8159 - val_dice_coef: 0.8159\n",
      "Epoch 58/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9612 - dice_coef: 0.9612 - val_loss: -0.8198 - val_dice_coef: 0.8198\n",
      "Epoch 59/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9627 - dice_coef: 0.9627 - val_loss: -0.8171 - val_dice_coef: 0.8171\n",
      "Epoch 60/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9640 - dice_coef: 0.9640 - val_loss: -0.8085 - val_dice_coef: 0.8085\n",
      "Epoch 61/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9628 - dice_coef: 0.9628 - val_loss: -0.8168 - val_dice_coef: 0.8168\n",
      "Epoch 62/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9643 - dice_coef: 0.9643 - val_loss: -0.8154 - val_dice_coef: 0.8154\n",
      "Epoch 63/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9642 - dice_coef: 0.9642 - val_loss: -0.8135 - val_dice_coef: 0.8135\n",
      "Epoch 64/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9641 - dice_coef: 0.9641 - val_loss: -0.8187 - val_dice_coef: 0.8187\n",
      "Epoch 65/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9662 - dice_coef: 0.9662 - val_loss: -0.8161 - val_dice_coef: 0.8161\n",
      "Epoch 66/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9648 - dice_coef: 0.9648 - val_loss: -0.8182 - val_dice_coef: 0.8182\n",
      "Epoch 67/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9653 - dice_coef: 0.9653 - val_loss: -0.8184 - val_dice_coef: 0.8184\n",
      "Epoch 68/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9632 - dice_coef: 0.9632 - val_loss: -0.8178 - val_dice_coef: 0.8178\n",
      "Epoch 69/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9653 - dice_coef: 0.9653 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 70/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9679 - dice_coef: 0.9679 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 71/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9677 - dice_coef: 0.9677 - val_loss: -0.8178 - val_dice_coef: 0.8178\n",
      "Epoch 72/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9676 - dice_coef: 0.9676 - val_loss: -0.8181 - val_dice_coef: 0.8181\n",
      "Epoch 73/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9668 - dice_coef: 0.9668 - val_loss: -0.8183 - val_dice_coef: 0.8183\n",
      "Epoch 74/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9680 - dice_coef: 0.9680 - val_loss: -0.8188 - val_dice_coef: 0.8188\n",
      "Epoch 75/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9689 - dice_coef: 0.9689 - val_loss: -0.8172 - val_dice_coef: 0.8172\n",
      "Epoch 76/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9677 - dice_coef: 0.9677 - val_loss: -0.8168 - val_dice_coef: 0.8168\n",
      "Epoch 77/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9663 - dice_coef: 0.9663 - val_loss: -0.8147 - val_dice_coef: 0.8147\n",
      "Epoch 78/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9689 - dice_coef: 0.9689 - val_loss: -0.8124 - val_dice_coef: 0.8124\n",
      "Epoch 79/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9696 - dice_coef: 0.9696 - val_loss: -0.8184 - val_dice_coef: 0.8184\n",
      "Epoch 80/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9690 - dice_coef: 0.9690 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 81/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9688 - dice_coef: 0.9688 - val_loss: -0.8191 - val_dice_coef: 0.8191\n",
      "Epoch 82/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9701 - dice_coef: 0.9701 - val_loss: -0.8181 - val_dice_coef: 0.8181\n",
      "Epoch 83/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9708 - dice_coef: 0.9708 - val_loss: -0.8168 - val_dice_coef: 0.8168\n",
      "Epoch 84/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9679 - dice_coef: 0.9679 - val_loss: -0.8141 - val_dice_coef: 0.8141\n",
      "Epoch 85/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9698 - dice_coef: 0.9698 - val_loss: -0.8148 - val_dice_coef: 0.8148\n",
      "Epoch 86/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9702 - dice_coef: 0.9702 - val_loss: -0.8125 - val_dice_coef: 0.8125\n",
      "Epoch 87/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9708 - dice_coef: 0.9708 - val_loss: -0.8153 - val_dice_coef: 0.8153\n",
      "Epoch 88/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9725 - dice_coef: 0.9725 - val_loss: -0.8188 - val_dice_coef: 0.8188\n",
      "Epoch 89/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9725 - dice_coef: 0.9725 - val_loss: -0.8157 - val_dice_coef: 0.8157\n",
      "Epoch 90/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9708 - dice_coef: 0.9708 - val_loss: -0.8173 - val_dice_coef: 0.8173\n",
      "Epoch 91/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9698 - dice_coef: 0.9698 - val_loss: -0.8165 - val_dice_coef: 0.8165\n",
      "Epoch 92/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9712 - dice_coef: 0.9712 - val_loss: -0.8168 - val_dice_coef: 0.8168\n",
      "Epoch 93/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9716 - dice_coef: 0.9716 - val_loss: -0.8205 - val_dice_coef: 0.8205\n",
      "Epoch 94/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9693 - dice_coef: 0.9693 - val_loss: -0.8164 - val_dice_coef: 0.8164\n",
      "Epoch 95/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9721 - dice_coef: 0.9721 - val_loss: -0.8183 - val_dice_coef: 0.8183\n",
      "Epoch 96/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9728 - dice_coef: 0.9728 - val_loss: -0.8173 - val_dice_coef: 0.8173\n",
      "Epoch 97/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9700 - dice_coef: 0.9700 - val_loss: -0.8186 - val_dice_coef: 0.8186\n",
      "Epoch 98/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9718 - dice_coef: 0.9718 - val_loss: -0.8198 - val_dice_coef: 0.8198\n",
      "Epoch 99/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9714 - dice_coef: 0.9714 - val_loss: -0.8191 - val_dice_coef: 0.8191\n",
      "Epoch 100/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9696 - dice_coef: 0.9696 - val_loss: -0.8180 - val_dice_coef: 0.8180\n",
      "Epoch 101/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9724 - dice_coef: 0.9724 - val_loss: -0.8197 - val_dice_coef: 0.8197\n",
      "Epoch 102/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9726 - dice_coef: 0.9726 - val_loss: -0.8209 - val_dice_coef: 0.8209\n",
      "Epoch 103/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9738 - dice_coef: 0.9738 - val_loss: -0.8209 - val_dice_coef: 0.8209\n",
      "Epoch 104/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9718 - dice_coef: 0.9718 - val_loss: -0.8152 - val_dice_coef: 0.8152\n",
      "Epoch 105/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9720 - dice_coef: 0.9720 - val_loss: -0.8196 - val_dice_coef: 0.8196\n",
      "Epoch 106/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9716 - dice_coef: 0.9716 - val_loss: -0.8192 - val_dice_coef: 0.8192\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9742 - dice_coef: 0.9742 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 108/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9743 - dice_coef: 0.9743 - val_loss: -0.8190 - val_dice_coef: 0.8190\n",
      "Epoch 109/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9740 - dice_coef: 0.9740 - val_loss: -0.8191 - val_dice_coef: 0.8191\n",
      "Epoch 110/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9722 - dice_coef: 0.9722 - val_loss: -0.8193 - val_dice_coef: 0.8193\n",
      "Epoch 111/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9735 - dice_coef: 0.9735 - val_loss: -0.8174 - val_dice_coef: 0.8174\n",
      "Epoch 112/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9738 - dice_coef: 0.9738 - val_loss: -0.8203 - val_dice_coef: 0.8203\n",
      "Epoch 113/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9743 - dice_coef: 0.9743 - val_loss: -0.8204 - val_dice_coef: 0.8204\n",
      "Epoch 114/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9736 - dice_coef: 0.9736 - val_loss: -0.8200 - val_dice_coef: 0.8200\n",
      "Epoch 115/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9752 - dice_coef: 0.9752 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 116/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9751 - dice_coef: 0.9751 - val_loss: -0.8192 - val_dice_coef: 0.8192\n",
      "Epoch 117/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9732 - dice_coef: 0.9732 - val_loss: -0.8190 - val_dice_coef: 0.8190\n",
      "Epoch 118/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9724 - dice_coef: 0.9724 - val_loss: -0.8189 - val_dice_coef: 0.8189\n",
      "Epoch 119/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9742 - dice_coef: 0.9742 - val_loss: -0.8208 - val_dice_coef: 0.8208\n",
      "Epoch 120/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9760 - dice_coef: 0.9760 - val_loss: -0.8220 - val_dice_coef: 0.8220\n",
      "Epoch 121/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9749 - dice_coef: 0.9749 - val_loss: -0.8200 - val_dice_coef: 0.8200\n",
      "Epoch 122/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9747 - dice_coef: 0.9747 - val_loss: -0.8204 - val_dice_coef: 0.8204\n",
      "Epoch 123/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9752 - dice_coef: 0.9752 - val_loss: -0.8193 - val_dice_coef: 0.8193\n",
      "Epoch 124/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9757 - dice_coef: 0.9757 - val_loss: -0.8198 - val_dice_coef: 0.8198\n",
      "Epoch 125/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9745 - dice_coef: 0.9745 - val_loss: -0.8193 - val_dice_coef: 0.8193\n",
      "Epoch 126/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9745 - dice_coef: 0.9745 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 127/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9744 - dice_coef: 0.9744 - val_loss: -0.8198 - val_dice_coef: 0.8198\n",
      "Epoch 128/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9746 - dice_coef: 0.9746 - val_loss: -0.8189 - val_dice_coef: 0.8189\n",
      "Epoch 129/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9759 - dice_coef: 0.9759 - val_loss: -0.8196 - val_dice_coef: 0.8196\n",
      "Epoch 130/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9755 - dice_coef: 0.9755 - val_loss: -0.8152 - val_dice_coef: 0.8152\n",
      "Epoch 131/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9763 - dice_coef: 0.9763 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 132/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9749 - dice_coef: 0.9749 - val_loss: -0.8217 - val_dice_coef: 0.8217\n",
      "Epoch 133/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9740 - dice_coef: 0.9740 - val_loss: -0.8237 - val_dice_coef: 0.8237\n",
      "Epoch 134/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9758 - dice_coef: 0.9758 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 135/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9759 - dice_coef: 0.9759 - val_loss: -0.8251 - val_dice_coef: 0.8251\n",
      "Epoch 136/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9755 - dice_coef: 0.9755 - val_loss: -0.8173 - val_dice_coef: 0.8173\n",
      "Epoch 137/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9755 - dice_coef: 0.9755 - val_loss: -0.8200 - val_dice_coef: 0.8200\n",
      "Epoch 138/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9758 - dice_coef: 0.9758 - val_loss: -0.8216 - val_dice_coef: 0.8216\n",
      "Epoch 139/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9762 - dice_coef: 0.9762 - val_loss: -0.8201 - val_dice_coef: 0.8201\n",
      "Epoch 140/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9763 - dice_coef: 0.9763 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 141/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9764 - dice_coef: 0.9764 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 142/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9767 - dice_coef: 0.9767 - val_loss: -0.8214 - val_dice_coef: 0.8214\n",
      "Epoch 143/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9771 - dice_coef: 0.9771 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 144/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9747 - dice_coef: 0.9747 - val_loss: -0.8217 - val_dice_coef: 0.8217\n",
      "Epoch 145/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9748 - dice_coef: 0.9748 - val_loss: -0.8234 - val_dice_coef: 0.8234\n",
      "Epoch 146/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9764 - dice_coef: 0.9764 - val_loss: -0.8217 - val_dice_coef: 0.8217\n",
      "Epoch 147/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9767 - dice_coef: 0.9767 - val_loss: -0.8201 - val_dice_coef: 0.8201\n",
      "Epoch 148/200\n",
      "7800/7800 [==============================] - 309s 40ms/step - loss: -0.9763 - dice_coef: 0.9763 - val_loss: -0.8175 - val_dice_coef: 0.8175\n",
      "Epoch 149/200\n",
      "7800/7800 [==============================] - 310s 40ms/step - loss: -0.9771 - dice_coef: 0.9771 - val_loss: -0.8215 - val_dice_coef: 0.8215\n",
      "Epoch 150/200\n",
      "7800/7800 [==============================] - 307s 39ms/step - loss: -0.9765 - dice_coef: 0.9765 - val_loss: -0.8216 - val_dice_coef: 0.8216\n",
      "Epoch 151/200\n",
      "7800/7800 [==============================] - 307s 39ms/step - loss: -0.9765 - dice_coef: 0.9765 - val_loss: -0.8207 - val_dice_coef: 0.8207\n",
      "Epoch 152/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9759 - dice_coef: 0.9759 - val_loss: -0.8222 - val_dice_coef: 0.8222\n",
      "Epoch 153/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9769 - dice_coef: 0.9769 - val_loss: -0.8206 - val_dice_coef: 0.8206\n",
      "Epoch 154/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9775 - dice_coef: 0.9775 - val_loss: -0.8223 - val_dice_coef: 0.8223\n",
      "Epoch 155/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9765 - dice_coef: 0.9765 - val_loss: -0.8219 - val_dice_coef: 0.8219\n",
      "Epoch 156/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9771 - dice_coef: 0.9771 - val_loss: -0.8210 - val_dice_coef: 0.8210\n",
      "Epoch 157/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9767 - dice_coef: 0.9767 - val_loss: -0.8207 - val_dice_coef: 0.8207\n",
      "Epoch 158/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9776 - dice_coef: 0.9776 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 159/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9777 - dice_coef: 0.9777 - val_loss: -0.8194 - val_dice_coef: 0.8194\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.8239 - val_dice_coef: 0.8239\n",
      "Epoch 161/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9777 - dice_coef: 0.9777 - val_loss: -0.8204 - val_dice_coef: 0.8204\n",
      "Epoch 162/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9761 - dice_coef: 0.9761 - val_loss: -0.8218 - val_dice_coef: 0.8218\n",
      "Epoch 163/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9779 - dice_coef: 0.9779 - val_loss: -0.8236 - val_dice_coef: 0.8236\n",
      "Epoch 164/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9782 - dice_coef: 0.9782 - val_loss: -0.8221 - val_dice_coef: 0.8221\n",
      "Epoch 165/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9777 - dice_coef: 0.9777 - val_loss: -0.8230 - val_dice_coef: 0.8230\n",
      "Epoch 166/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9776 - dice_coef: 0.9776 - val_loss: -0.8217 - val_dice_coef: 0.8217\n",
      "Epoch 167/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9781 - dice_coef: 0.9781 - val_loss: -0.8210 - val_dice_coef: 0.8210\n",
      "Epoch 168/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9775 - dice_coef: 0.9775 - val_loss: -0.8174 - val_dice_coef: 0.8174\n",
      "Epoch 169/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9775 - dice_coef: 0.9775 - val_loss: -0.8236 - val_dice_coef: 0.8236\n",
      "Epoch 170/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9765 - dice_coef: 0.9765 - val_loss: -0.8238 - val_dice_coef: 0.8238\n",
      "Epoch 171/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.8224 - val_dice_coef: 0.8224\n",
      "Epoch 172/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9784 - dice_coef: 0.9784 - val_loss: -0.8233 - val_dice_coef: 0.8233\n",
      "Epoch 173/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.8248 - val_dice_coef: 0.8248\n",
      "Epoch 174/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9784 - dice_coef: 0.9784 - val_loss: -0.8192 - val_dice_coef: 0.8192\n",
      "Epoch 175/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9779 - dice_coef: 0.9779 - val_loss: -0.8247 - val_dice_coef: 0.8247\n",
      "Epoch 176/200\n",
      "7800/7800 [==============================] - 307s 39ms/step - loss: -0.9782 - dice_coef: 0.9782 - val_loss: -0.8222 - val_dice_coef: 0.8222\n",
      "Epoch 177/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9776 - dice_coef: 0.9776 - val_loss: -0.8248 - val_dice_coef: 0.8248\n",
      "Epoch 178/200\n",
      "7800/7800 [==============================] - 307s 39ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.8219 - val_dice_coef: 0.8219\n",
      "Epoch 179/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9786 - dice_coef: 0.9786 - val_loss: -0.8229 - val_dice_coef: 0.8229\n",
      "Epoch 180/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9791 - dice_coef: 0.9791 - val_loss: -0.8212 - val_dice_coef: 0.8212\n",
      "Epoch 181/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.8203 - val_dice_coef: 0.8203\n",
      "Epoch 182/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.8226 - val_dice_coef: 0.8226\n",
      "Epoch 183/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.8271 - val_dice_coef: 0.8271\n",
      "Epoch 184/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9782 - dice_coef: 0.9782 - val_loss: -0.8230 - val_dice_coef: 0.8230\n",
      "Epoch 185/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9776 - dice_coef: 0.9776 - val_loss: -0.8230 - val_dice_coef: 0.8230\n",
      "Epoch 186/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9783 - dice_coef: 0.9783 - val_loss: -0.8245 - val_dice_coef: 0.8245\n",
      "Epoch 187/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9775 - dice_coef: 0.9775 - val_loss: -0.8261 - val_dice_coef: 0.8261\n",
      "Epoch 188/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9791 - dice_coef: 0.9791 - val_loss: -0.8226 - val_dice_coef: 0.8226\n",
      "Epoch 189/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9794 - dice_coef: 0.9794 - val_loss: -0.8250 - val_dice_coef: 0.8250\n",
      "Epoch 190/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.8226 - val_dice_coef: 0.8226\n",
      "Epoch 191/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9797 - dice_coef: 0.9797 - val_loss: -0.8233 - val_dice_coef: 0.8233\n",
      "Epoch 192/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9790 - dice_coef: 0.9790 - val_loss: -0.8242 - val_dice_coef: 0.8242\n",
      "Epoch 193/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9789 - dice_coef: 0.9789 - val_loss: -0.8244 - val_dice_coef: 0.8244\n",
      "Epoch 194/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9791 - dice_coef: 0.9791 - val_loss: -0.8221 - val_dice_coef: 0.8221\n",
      "Epoch 195/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9795 - dice_coef: 0.9795 - val_loss: -0.8252 - val_dice_coef: 0.8252\n",
      "Epoch 196/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9792 - dice_coef: 0.9792 - val_loss: -0.8252 - val_dice_coef: 0.8252\n",
      "Epoch 197/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.8214 - val_dice_coef: 0.8214\n",
      "Epoch 198/200\n",
      "7800/7800 [==============================] - 307s 39ms/step - loss: -0.9795 - dice_coef: 0.9795 - val_loss: -0.8252 - val_dice_coef: 0.8252\n",
      "Epoch 199/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9799 - dice_coef: 0.9799 - val_loss: -0.8239 - val_dice_coef: 0.8239\n",
      "Epoch 200/200\n",
      "7800/7800 [==============================] - 306s 39ms/step - loss: -0.9791 - dice_coef: 0.9791 - val_loss: -0.8192 - val_dice_coef: 0.8192\n"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    print('start training...')\n",
    "    history = model_fcn00.fit(X_train[:,:,:,:], Y_train[:,:,:,:], batch_size=64, epochs=200, verbose=1,\n",
    "                  shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Save History\n",
    "    f = open(dname_checkpoints + '/' + fname_history,'wb')\n",
    "    pickle.dump(history.history,f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_fcn00.augumented/history.pkl\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-66838d064e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    #   Show History\n",
    "    #\n",
    "\n",
    "    # load pickle\n",
    "    print(dname_checkpoints + '/' + fname_history)\n",
    "    history = pickle.load(open(dname_checkpoints + '/' + fname_history, 'rb'))\n",
    "\n",
    "    for k in history.keys():\n",
    "        plt.plot(history[k])\n",
    "        plt.title(k)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
