{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/nakazawa_atsushi/anaconda3/envs/py3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "#   LEARN FCN00\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, AveragePooling2D\n",
    "from keras.layers import merge\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.preprocessing.image import list_pictures, array_to_img\n",
    "\n",
    "from image_ext import list_pictures_in_multidir, load_imgs_asarray, img_dice_coeff\n",
    "from fname_func import load_fnames, make_fnames\n",
    "\n",
    "# MAXPOOLING\n",
    "from create_fcn import create_fcn01, create_fcn00\n",
    "# AVERAGE POOLING\n",
    "#from create_fcn_avpool import create_fcn01,create_fcn00\n",
    "\n",
    "np.random.seed(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    return (2.*intersection + 1) / (K.sum(y_true) + K.sum(y_pred) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model fcn00...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  MAIN STARTS FROM HERE\n",
    "#\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    target_size = (224, 224)\n",
    "    dpath_this = './'\n",
    "    dname_checkpoints = 'checkpoints_fcn00.augumented_2.alldata'\n",
    "    dname_checkpoints_fcn01 = 'checkpoints_fcn01'\n",
    "    dname_outputs = 'outputs'\n",
    "    fname_architecture = 'architecture.json'\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fname_stats = 'stats01.npz'\n",
    "    dim_ordering = 'channels_first'\n",
    "    fname_history = \"history.pkl\"\n",
    "\n",
    "    # モデルを作成\n",
    "    print('creating model fcn00...')\n",
    "    model_fcn00 = create_fcn00(target_size)\n",
    "    \n",
    "    if os.path.exists(dname_checkpoints) == 0:\n",
    "        os.mkdir(dname_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading training data\n",
      "reading traking gt data\n"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    #   LEARNING MODE\n",
    "    #\n",
    "    # Read Learning Data\n",
    "    #    fnames = load_fnames('data/list_train_01.txt')\n",
    "    #    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    #    fnames = load_fnames('data.nnlab/list_train_01.txt')\n",
    "    #    fnames = load_fnames('data/list_train_01.txt')\n",
    "    fnames = load_fnames('data_augumented_2/list_all.txt')\n",
    "    #    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data.nnlab/image','data.nnlab/gt','')\n",
    "    [fpaths_xs_train,fpaths_ys_train] = make_fnames(fnames,'data_augumented_2/img','data_augumented_2/mask','')\n",
    "\n",
    "    print('reading training data')\n",
    "    X_train = load_imgs_asarray(fpaths_xs_train, grayscale=False, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering)\n",
    "    print('reading traking gt data')\n",
    "    Y_train = load_imgs_asarray(fpaths_ys_train, grayscale=True, target_size=target_size,\n",
    "                                dim_ordering=dim_ordering) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 15743 training images loaded\n",
      "==> 15743 training masks loaded\n",
      "==> 0 validation images loaded\n",
      "==> 0 validation masks loaded\n",
      "computing mean and standard deviation...\n",
      "==> mean: [126.13108   90.505585  78.30973 ]\n",
      "==> std : [60.968956 47.603256 52.209408]\n"
     ]
    }
   ],
   "source": [
    "    # Read Validation Data\n",
    "    #    fnames = load_fnames('data/list_valid_01.txt')\n",
    "    #    [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data/img','data/mask','OperatorA_')\n",
    "    #fnames = load_fnames('data_augumented_2/list_valid_01.txt')\n",
    "    # [fpaths_xs_valid,fpaths_ys_valid] = make_fnames(fnames,'data_augumented_2/img','data_augumented_2/mask','')\n",
    "    VALIDATION = 0\n",
    "\n",
    "    if VALIDATION == 1:\n",
    "        print('reading validation data')\n",
    "        X_valid = load_imgs_asarray(fpaths_xs_valid, grayscale=False, target_size=target_size,\n",
    "                                    dim_ordering=dim_ordering)\n",
    "        Y_valid = load_imgs_asarray(fpaths_ys_valid, grayscale=True, target_size=target_size,\n",
    "                                    dim_ordering=dim_ordering)  \n",
    "    else:\n",
    "        X_valid = []\n",
    "        Y_valid = []\n",
    "\n",
    "    print('==> ' + str(len(X_train)) + ' training images loaded')\n",
    "    print('==> ' + str(len(Y_train)) + ' training masks loaded')\n",
    "    print('==> ' + str(len(X_valid)) + ' validation images loaded')\n",
    "    print('==> ' + str(len(Y_valid)) + ' validation masks loaded')\n",
    "\n",
    "    # 前処理\n",
    "    print('computing mean and standard deviation...')\n",
    "    mean = np.mean(X_train, axis=(0, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 2, 3))\n",
    "    print('==> mean: ' + str(mean))\n",
    "    print('==> std : ' + str(std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving mean and standard deviation to stats01.npz...\n",
      "==> done\n",
      "globally normalizing data...\n",
      "==> done\n"
     ]
    }
   ],
   "source": [
    "    print('saving mean and standard deviation to ' + fname_stats + '...')\n",
    "    stats = {'mean': mean, 'std': std}\n",
    "    np.savez(dname_checkpoints + '/' + fname_stats, **stats)\n",
    "    print('==> done')\n",
    "\n",
    "    print('globally normalizing data...')\n",
    "    for i in range(3):\n",
    "        X_train[:, i] = (X_train[:, i] - mean[i]) / std[i]\n",
    "        if VALIDATION == 1:\n",
    "            X_valid[:, i] = (X_valid[:, i] - mean[i]) / std[i]\n",
    "    \n",
    "    Y_train /= 255\n",
    "    \n",
    "    if VALIDATION == 1:\n",
    "        Y_train_valid /= 255\n",
    "    print('==> done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying layer weights\n",
      "conv1_1\n",
      "conv1_2\n",
      "conv2_1\n",
      "conv2_2\n",
      "up1_1\n",
      "up1_2\n",
      "up2_1\n",
      "up2_2\n",
      "conv_fin\n"
     ]
    }
   ],
   "source": [
    "    init_from_fcn01 = 1\n",
    "    \n",
    "    if init_from_fcn01 == 1:\n",
    "        # モデルに学習済のfcn01 Weightをロードする\n",
    "        model_fcn01 = create_fcn01(target_size)        \n",
    "        epoch = 100\n",
    "        fname_weights = 'model_weights_%02d.h5'%(epoch)\n",
    "        fpath_weights_fcn01 = os.path.join(dname_checkpoints_fcn01, fname_weights)\n",
    "        model_fcn01.load_weights(fpath_weights_fcn01)\n",
    "        #print('==> done')\n",
    "\n",
    "        # load weights from Learned U-NET\n",
    "        layer_names = ['conv1_1','conv1_2','conv2_1','conv2_2','conv3_1','conv3_2',\n",
    "                       'conv4_1','conv4_2','conv5_1', 'conv5_2',\n",
    "                    'up1_1', 'up1_2', 'up2_1', 'up2_2', 'up3_1', 'up3_2', 'up4_1', \n",
    "                       'up4_2', 'conv_fin']\n",
    "        layer_names = ['conv1_1','conv1_2','conv2_1','conv2_2',\n",
    "                    'up1_1', 'up1_2', 'up2_1', 'up2_2', 'conv_fin']\n",
    "\n",
    "        print('copying layer weights')\n",
    "        for name in layer_names:\n",
    "            print(name)\n",
    "            model_fcn00.get_layer(name).set_weights(model_fcn01.get_layer(name).get_weights())\n",
    "            model_fcn00.get_layer(name).trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 損失関数，最適化手法を定義\n",
    "    adam = Adam(lr=1e-5)\n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "    #rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model_fcn00.compile(optimizer=adam, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    # 構造・重みを保存するディレクトリーの有無を確認\n",
    "    dpath_checkpoints = os.path.join(dpath_this, dname_checkpoints)\n",
    "    if not os.path.isdir(dpath_checkpoints):\n",
    "        os.mkdir(dpath_checkpoints)\n",
    "\n",
    "    # 重みを保存するためのオブジェクトを用意\n",
    "    fname_weights = \"model_weights_{epoch:02d}.h5\"\n",
    "    fpath_weights = os.path.join(dpath_checkpoints, fname_weights)\n",
    "    checkpointer = ModelCheckpoint(filepath=fpath_weights, save_best_only=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "Train on 14168 samples, validate on 1575 samples\n",
      "Epoch 1/200\n",
      "14168/14168 [==============================] - 603s 43ms/step - loss: -0.5955 - dice_coef: 0.5955 - val_loss: -0.7549 - val_dice_coef: 0.7549\n",
      "Epoch 2/200\n",
      "14168/14168 [==============================] - 577s 41ms/step - loss: -0.7496 - dice_coef: 0.7496 - val_loss: -0.8246 - val_dice_coef: 0.8246\n",
      "Epoch 3/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.7819 - dice_coef: 0.7819 - val_loss: -0.8289 - val_dice_coef: 0.8289\n",
      "Epoch 4/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8075 - dice_coef: 0.8075 - val_loss: -0.8493 - val_dice_coef: 0.8493\n",
      "Epoch 5/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8225 - dice_coef: 0.8225 - val_loss: -0.8650 - val_dice_coef: 0.8650\n",
      "Epoch 6/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8365 - dice_coef: 0.8365 - val_loss: -0.8736 - val_dice_coef: 0.8736\n",
      "Epoch 7/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8505 - dice_coef: 0.8505 - val_loss: -0.8785 - val_dice_coef: 0.8785\n",
      "Epoch 8/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8648 - dice_coef: 0.8648 - val_loss: -0.8878 - val_dice_coef: 0.8878\n",
      "Epoch 9/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8784 - dice_coef: 0.8784 - val_loss: -0.8746 - val_dice_coef: 0.8746\n",
      "Epoch 10/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.8862 - dice_coef: 0.8862 - val_loss: -0.9024 - val_dice_coef: 0.9024\n",
      "Epoch 11/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.8964 - dice_coef: 0.8964 - val_loss: -0.8912 - val_dice_coef: 0.8912\n",
      "Epoch 12/200\n",
      "14168/14168 [==============================] - 576s 41ms/step - loss: -0.9011 - dice_coef: 0.9011 - val_loss: -0.9091 - val_dice_coef: 0.9091\n",
      "Epoch 13/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9108 - dice_coef: 0.9108 - val_loss: -0.9218 - val_dice_coef: 0.9218\n",
      "Epoch 14/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9165 - dice_coef: 0.9165 - val_loss: -0.9230 - val_dice_coef: 0.9230\n",
      "Epoch 15/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9211 - dice_coef: 0.9211 - val_loss: -0.9213 - val_dice_coef: 0.9213\n",
      "Epoch 16/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9263 - dice_coef: 0.9263 - val_loss: -0.9132 - val_dice_coef: 0.9132\n",
      "Epoch 17/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9294 - dice_coef: 0.9294 - val_loss: -0.9258 - val_dice_coef: 0.9258\n",
      "Epoch 18/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9341 - dice_coef: 0.9341 - val_loss: -0.9373 - val_dice_coef: 0.9373\n",
      "Epoch 19/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9377 - dice_coef: 0.9377 - val_loss: -0.9377 - val_dice_coef: 0.9377\n",
      "Epoch 20/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9382 - dice_coef: 0.9382 - val_loss: -0.9391 - val_dice_coef: 0.9391\n",
      "Epoch 21/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9423 - dice_coef: 0.9423 - val_loss: -0.9325 - val_dice_coef: 0.9325\n",
      "Epoch 22/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9439 - dice_coef: 0.9439 - val_loss: -0.9404 - val_dice_coef: 0.9404\n",
      "Epoch 23/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9467 - dice_coef: 0.9467 - val_loss: -0.9407 - val_dice_coef: 0.9407\n",
      "Epoch 24/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9475 - dice_coef: 0.9475 - val_loss: -0.9477 - val_dice_coef: 0.9477\n",
      "Epoch 25/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9486 - dice_coef: 0.9486 - val_loss: -0.9424 - val_dice_coef: 0.9424\n",
      "Epoch 26/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9511 - dice_coef: 0.9511 - val_loss: -0.9453 - val_dice_coef: 0.9453\n",
      "Epoch 27/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9522 - dice_coef: 0.9522 - val_loss: -0.9453 - val_dice_coef: 0.9453\n",
      "Epoch 28/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9531 - dice_coef: 0.9531 - val_loss: -0.9443 - val_dice_coef: 0.9443\n",
      "Epoch 29/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9553 - dice_coef: 0.9553 - val_loss: -0.9427 - val_dice_coef: 0.9427\n",
      "Epoch 30/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9541 - dice_coef: 0.9541 - val_loss: -0.9428 - val_dice_coef: 0.9428\n",
      "Epoch 31/200\n",
      "14168/14168 [==============================] - 575s 41ms/step - loss: -0.9547 - dice_coef: 0.9547 - val_loss: -0.9473 - val_dice_coef: 0.9473\n",
      "Epoch 32/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9565 - dice_coef: 0.9565 - val_loss: -0.9509 - val_dice_coef: 0.9509\n",
      "Epoch 33/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9575 - dice_coef: 0.9575 - val_loss: -0.9504 - val_dice_coef: 0.9504\n",
      "Epoch 34/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9582 - dice_coef: 0.9582 - val_loss: -0.9490 - val_dice_coef: 0.9490\n",
      "Epoch 35/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9582 - dice_coef: 0.9582 - val_loss: -0.9527 - val_dice_coef: 0.9527\n",
      "Epoch 36/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9601 - dice_coef: 0.9601 - val_loss: -0.9449 - val_dice_coef: 0.9449\n",
      "Epoch 37/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9596 - dice_coef: 0.9596 - val_loss: -0.9423 - val_dice_coef: 0.9423\n",
      "Epoch 38/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9603 - dice_coef: 0.9603 - val_loss: -0.9531 - val_dice_coef: 0.9531\n",
      "Epoch 39/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9616 - dice_coef: 0.9616 - val_loss: -0.9558 - val_dice_coef: 0.9558\n",
      "Epoch 40/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9623 - dice_coef: 0.9623 - val_loss: -0.9388 - val_dice_coef: 0.9388\n",
      "Epoch 41/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9621 - dice_coef: 0.9621 - val_loss: -0.9511 - val_dice_coef: 0.9511\n",
      "Epoch 42/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9629 - dice_coef: 0.9629 - val_loss: -0.9563 - val_dice_coef: 0.9563\n",
      "Epoch 43/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9635 - dice_coef: 0.9635 - val_loss: -0.9588 - val_dice_coef: 0.9588\n",
      "Epoch 44/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9642 - dice_coef: 0.9642 - val_loss: -0.9566 - val_dice_coef: 0.9566\n",
      "Epoch 45/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9643 - dice_coef: 0.9643 - val_loss: -0.9570 - val_dice_coef: 0.9570\n",
      "Epoch 46/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9645 - dice_coef: 0.9645 - val_loss: -0.9575 - val_dice_coef: 0.9575\n",
      "Epoch 47/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9651 - dice_coef: 0.9651 - val_loss: -0.9526 - val_dice_coef: 0.9526\n",
      "Epoch 48/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9654 - dice_coef: 0.9654 - val_loss: -0.9575 - val_dice_coef: 0.9575\n",
      "Epoch 49/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9648 - dice_coef: 0.9648 - val_loss: -0.9566 - val_dice_coef: 0.9566\n",
      "Epoch 50/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9657 - dice_coef: 0.9657 - val_loss: -0.9574 - val_dice_coef: 0.9574\n",
      "Epoch 51/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9657 - dice_coef: 0.9657 - val_loss: -0.9486 - val_dice_coef: 0.9486\n",
      "Epoch 52/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9666 - dice_coef: 0.9666 - val_loss: -0.9607 - val_dice_coef: 0.9607\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9672 - dice_coef: 0.9672 - val_loss: -0.9579 - val_dice_coef: 0.9579\n",
      "Epoch 54/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9675 - dice_coef: 0.9675 - val_loss: -0.9554 - val_dice_coef: 0.9554\n",
      "Epoch 55/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9671 - dice_coef: 0.9671 - val_loss: -0.9593 - val_dice_coef: 0.9593\n",
      "Epoch 56/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9675 - dice_coef: 0.9675 - val_loss: -0.9611 - val_dice_coef: 0.9611\n",
      "Epoch 57/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9675 - dice_coef: 0.9675 - val_loss: -0.9617 - val_dice_coef: 0.9617\n",
      "Epoch 58/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9690 - dice_coef: 0.9690 - val_loss: -0.9622 - val_dice_coef: 0.9622\n",
      "Epoch 59/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9690 - dice_coef: 0.9690 - val_loss: -0.9603 - val_dice_coef: 0.9603\n",
      "Epoch 60/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9686 - dice_coef: 0.9686 - val_loss: -0.9595 - val_dice_coef: 0.9595\n",
      "Epoch 61/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9687 - dice_coef: 0.9687 - val_loss: -0.9623 - val_dice_coef: 0.9623\n",
      "Epoch 62/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9693 - dice_coef: 0.9693 - val_loss: -0.9632 - val_dice_coef: 0.9632\n",
      "Epoch 63/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9701 - dice_coef: 0.9701 - val_loss: -0.9545 - val_dice_coef: 0.9545\n",
      "Epoch 64/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9699 - dice_coef: 0.9699 - val_loss: -0.9609 - val_dice_coef: 0.9609\n",
      "Epoch 65/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9692 - dice_coef: 0.9692 - val_loss: -0.9613 - val_dice_coef: 0.9613\n",
      "Epoch 66/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9704 - dice_coef: 0.9704 - val_loss: -0.9603 - val_dice_coef: 0.9603\n",
      "Epoch 67/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9707 - dice_coef: 0.9707 - val_loss: -0.9628 - val_dice_coef: 0.9628\n",
      "Epoch 68/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9701 - dice_coef: 0.9701 - val_loss: -0.9607 - val_dice_coef: 0.9607\n",
      "Epoch 69/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9702 - dice_coef: 0.9702 - val_loss: -0.9627 - val_dice_coef: 0.9627\n",
      "Epoch 70/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9705 - dice_coef: 0.9705 - val_loss: -0.9613 - val_dice_coef: 0.9613\n",
      "Epoch 71/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9709 - dice_coef: 0.9709 - val_loss: -0.9639 - val_dice_coef: 0.9639\n",
      "Epoch 72/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9711 - dice_coef: 0.9711 - val_loss: -0.9639 - val_dice_coef: 0.9639\n",
      "Epoch 73/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9723 - dice_coef: 0.9723 - val_loss: -0.9633 - val_dice_coef: 0.9633\n",
      "Epoch 74/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9714 - dice_coef: 0.9714 - val_loss: -0.9645 - val_dice_coef: 0.9645\n",
      "Epoch 75/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9714 - dice_coef: 0.9714 - val_loss: -0.9650 - val_dice_coef: 0.9650\n",
      "Epoch 76/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9719 - dice_coef: 0.9719 - val_loss: -0.9641 - val_dice_coef: 0.9641\n",
      "Epoch 77/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9720 - dice_coef: 0.9720 - val_loss: -0.9635 - val_dice_coef: 0.9635\n",
      "Epoch 78/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9722 - dice_coef: 0.9722 - val_loss: -0.9622 - val_dice_coef: 0.9622\n",
      "Epoch 79/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9720 - dice_coef: 0.9720 - val_loss: -0.9638 - val_dice_coef: 0.9638\n",
      "Epoch 80/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9726 - dice_coef: 0.9726 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 81/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9730 - dice_coef: 0.9730 - val_loss: -0.9647 - val_dice_coef: 0.9647\n",
      "Epoch 82/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9729 - dice_coef: 0.9729 - val_loss: -0.9664 - val_dice_coef: 0.9664\n",
      "Epoch 83/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9724 - dice_coef: 0.9724 - val_loss: -0.9574 - val_dice_coef: 0.9574\n",
      "Epoch 84/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9729 - dice_coef: 0.9729 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 85/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9734 - dice_coef: 0.9734 - val_loss: -0.9656 - val_dice_coef: 0.9656\n",
      "Epoch 86/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9736 - dice_coef: 0.9736 - val_loss: -0.9625 - val_dice_coef: 0.9625\n",
      "Epoch 87/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9728 - dice_coef: 0.9728 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 88/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9736 - dice_coef: 0.9736 - val_loss: -0.9637 - val_dice_coef: 0.9637\n",
      "Epoch 89/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9737 - dice_coef: 0.9737 - val_loss: -0.9629 - val_dice_coef: 0.9629\n",
      "Epoch 90/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9738 - dice_coef: 0.9738 - val_loss: -0.9659 - val_dice_coef: 0.9659\n",
      "Epoch 91/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9744 - dice_coef: 0.9744 - val_loss: -0.9660 - val_dice_coef: 0.9660\n",
      "Epoch 92/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9740 - dice_coef: 0.9740 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 93/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9740 - dice_coef: 0.9740 - val_loss: -0.9669 - val_dice_coef: 0.9669\n",
      "Epoch 94/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9740 - dice_coef: 0.9740 - val_loss: -0.9676 - val_dice_coef: 0.9676\n",
      "Epoch 95/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9747 - dice_coef: 0.9747 - val_loss: -0.9654 - val_dice_coef: 0.9654\n",
      "Epoch 96/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9743 - dice_coef: 0.9743 - val_loss: -0.9663 - val_dice_coef: 0.9663\n",
      "Epoch 97/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9750 - dice_coef: 0.9750 - val_loss: -0.9652 - val_dice_coef: 0.9652\n",
      "Epoch 98/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9749 - dice_coef: 0.9749 - val_loss: -0.9654 - val_dice_coef: 0.9654\n",
      "Epoch 99/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9743 - dice_coef: 0.9743 - val_loss: -0.9670 - val_dice_coef: 0.9670\n",
      "Epoch 100/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9751 - dice_coef: 0.9751 - val_loss: -0.9665 - val_dice_coef: 0.9665\n",
      "Epoch 101/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9749 - dice_coef: 0.9749 - val_loss: -0.9672 - val_dice_coef: 0.9672\n",
      "Epoch 102/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9748 - dice_coef: 0.9748 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 103/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9752 - dice_coef: 0.9752 - val_loss: -0.9664 - val_dice_coef: 0.9664\n",
      "Epoch 104/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9754 - dice_coef: 0.9754 - val_loss: -0.9678 - val_dice_coef: 0.9678\n",
      "Epoch 105/200\n",
      "14168/14168 [==============================] - 573s 40ms/step - loss: -0.9753 - dice_coef: 0.9753 - val_loss: -0.9672 - val_dice_coef: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/200\n",
      "14168/14168 [==============================] - 574s 41ms/step - loss: -0.9753 - dice_coef: 0.9753 - val_loss: -0.9684 - val_dice_coef: 0.9684\n",
      "Epoch 107/200\n",
      "14168/14168 [==============================] - 574s 40ms/step - loss: -0.9758 - dice_coef: 0.9758 - val_loss: -0.9687 - val_dice_coef: 0.9687\n",
      "Epoch 108/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9760 - dice_coef: 0.9760 - val_loss: -0.9669 - val_dice_coef: 0.9669\n",
      "Epoch 109/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9756 - dice_coef: 0.9756 - val_loss: -0.9671 - val_dice_coef: 0.9671\n",
      "Epoch 110/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9755 - dice_coef: 0.9755 - val_loss: -0.9672 - val_dice_coef: 0.9672\n",
      "Epoch 111/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9758 - dice_coef: 0.9758 - val_loss: -0.9672 - val_dice_coef: 0.9672\n",
      "Epoch 112/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9757 - dice_coef: 0.9757 - val_loss: -0.9695 - val_dice_coef: 0.9695\n",
      "Epoch 113/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9760 - dice_coef: 0.9760 - val_loss: -0.9694 - val_dice_coef: 0.9694\n",
      "Epoch 114/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9760 - dice_coef: 0.9760 - val_loss: -0.9682 - val_dice_coef: 0.9682\n",
      "Epoch 115/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9764 - dice_coef: 0.9764 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 116/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9765 - dice_coef: 0.9765 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 117/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9769 - dice_coef: 0.9769 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 118/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9765 - dice_coef: 0.9765 - val_loss: -0.9658 - val_dice_coef: 0.9658\n",
      "Epoch 119/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9762 - dice_coef: 0.9762 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 120/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9764 - dice_coef: 0.9764 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 121/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9764 - dice_coef: 0.9764 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 122/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9767 - dice_coef: 0.9767 - val_loss: -0.9681 - val_dice_coef: 0.9681\n",
      "Epoch 123/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9767 - dice_coef: 0.9767 - val_loss: -0.9694 - val_dice_coef: 0.9694\n",
      "Epoch 124/200\n",
      "14168/14168 [==============================] - 570s 40ms/step - loss: -0.9769 - dice_coef: 0.9769 - val_loss: -0.9687 - val_dice_coef: 0.9687\n",
      "Epoch 125/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9767 - dice_coef: 0.9767 - val_loss: -0.9680 - val_dice_coef: 0.9680\n",
      "Epoch 126/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9772 - dice_coef: 0.9772 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 127/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9770 - dice_coef: 0.9770 - val_loss: -0.9692 - val_dice_coef: 0.9692\n",
      "Epoch 128/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9768 - dice_coef: 0.9768 - val_loss: -0.9689 - val_dice_coef: 0.9689\n",
      "Epoch 129/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9773 - dice_coef: 0.9773 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 130/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9771 - dice_coef: 0.9771 - val_loss: -0.9701 - val_dice_coef: 0.9701\n",
      "Epoch 131/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9771 - dice_coef: 0.9771 - val_loss: -0.9689 - val_dice_coef: 0.9689\n",
      "Epoch 132/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9776 - dice_coef: 0.9776 - val_loss: -0.9683 - val_dice_coef: 0.9683\n",
      "Epoch 133/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9773 - dice_coef: 0.9773 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 134/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9776 - dice_coef: 0.9776 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 135/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9777 - dice_coef: 0.9777 - val_loss: -0.9701 - val_dice_coef: 0.9701\n",
      "Epoch 136/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9774 - dice_coef: 0.9774 - val_loss: -0.9708 - val_dice_coef: 0.9708\n",
      "Epoch 137/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9779 - dice_coef: 0.9779 - val_loss: -0.9693 - val_dice_coef: 0.9693\n",
      "Epoch 138/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9778 - dice_coef: 0.9778 - val_loss: -0.9718 - val_dice_coef: 0.9718\n",
      "Epoch 139/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9780 - dice_coef: 0.9780 - val_loss: -0.9699 - val_dice_coef: 0.9699\n",
      "Epoch 140/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9782 - dice_coef: 0.9782 - val_loss: -0.9675 - val_dice_coef: 0.9675\n",
      "Epoch 141/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9777 - dice_coef: 0.9777 - val_loss: -0.9707 - val_dice_coef: 0.9707\n",
      "Epoch 142/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9778 - dice_coef: 0.9778 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 143/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9778 - dice_coef: 0.9778 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 144/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9781 - dice_coef: 0.9781 - val_loss: -0.9707 - val_dice_coef: 0.9707\n",
      "Epoch 145/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.9715 - val_dice_coef: 0.9715\n",
      "Epoch 146/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9784 - dice_coef: 0.9784 - val_loss: -0.9688 - val_dice_coef: 0.9688\n",
      "Epoch 147/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9786 - dice_coef: 0.9786 - val_loss: -0.9695 - val_dice_coef: 0.9695\n",
      "Epoch 148/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9784 - dice_coef: 0.9784 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 149/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9783 - dice_coef: 0.9783 - val_loss: -0.9712 - val_dice_coef: 0.9712\n",
      "Epoch 150/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9783 - dice_coef: 0.9783 - val_loss: -0.9700 - val_dice_coef: 0.9700\n",
      "Epoch 151/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9786 - dice_coef: 0.9786 - val_loss: -0.9707 - val_dice_coef: 0.9707\n",
      "Epoch 152/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.9711 - val_dice_coef: 0.9711\n",
      "Epoch 153/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9785 - dice_coef: 0.9785 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 154/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.9709 - val_dice_coef: 0.9709\n",
      "Epoch 155/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9791 - dice_coef: 0.9791 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 156/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9786 - dice_coef: 0.9786 - val_loss: -0.9703 - val_dice_coef: 0.9703\n",
      "Epoch 157/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9787 - dice_coef: 0.9787 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9790 - dice_coef: 0.9790 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 159/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9788 - dice_coef: 0.9788 - val_loss: -0.9726 - val_dice_coef: 0.9726\n",
      "Epoch 160/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9791 - dice_coef: 0.9791 - val_loss: -0.9700 - val_dice_coef: 0.9700\n",
      "Epoch 161/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9789 - dice_coef: 0.9789 - val_loss: -0.9710 - val_dice_coef: 0.9710\n",
      "Epoch 162/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9790 - dice_coef: 0.9790 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 163/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9793 - dice_coef: 0.9793 - val_loss: -0.9714 - val_dice_coef: 0.9714\n",
      "Epoch 164/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9790 - dice_coef: 0.9790 - val_loss: -0.9713 - val_dice_coef: 0.9713\n",
      "Epoch 165/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9789 - dice_coef: 0.9789 - val_loss: -0.9722 - val_dice_coef: 0.9722\n",
      "Epoch 166/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9793 - dice_coef: 0.9793 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 167/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9792 - dice_coef: 0.9792 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 168/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9794 - dice_coef: 0.9794 - val_loss: -0.9725 - val_dice_coef: 0.9725\n",
      "Epoch 169/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9792 - dice_coef: 0.9792 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 170/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9793 - dice_coef: 0.9793 - val_loss: -0.9730 - val_dice_coef: 0.9730\n",
      "Epoch 171/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9794 - dice_coef: 0.9794 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 172/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9797 - dice_coef: 0.9797 - val_loss: -0.9731 - val_dice_coef: 0.9731\n",
      "Epoch 173/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9793 - dice_coef: 0.9793 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 174/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9798 - dice_coef: 0.9798 - val_loss: -0.9725 - val_dice_coef: 0.9725\n",
      "Epoch 175/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9796 - dice_coef: 0.9796 - val_loss: -0.9719 - val_dice_coef: 0.9719\n",
      "Epoch 176/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9799 - dice_coef: 0.9799 - val_loss: -0.9720 - val_dice_coef: 0.9720\n",
      "Epoch 177/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9798 - dice_coef: 0.9798 - val_loss: -0.9711 - val_dice_coef: 0.9711\n",
      "Epoch 178/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9797 - dice_coef: 0.9797 - val_loss: -0.9727 - val_dice_coef: 0.9727\n",
      "Epoch 179/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9795 - dice_coef: 0.9795 - val_loss: -0.9742 - val_dice_coef: 0.9742\n",
      "Epoch 180/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9798 - dice_coef: 0.9798 - val_loss: -0.9727 - val_dice_coef: 0.9727\n",
      "Epoch 181/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9800 - dice_coef: 0.9800 - val_loss: -0.9739 - val_dice_coef: 0.9739\n",
      "Epoch 182/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9800 - dice_coef: 0.9800 - val_loss: -0.9738 - val_dice_coef: 0.9738\n",
      "Epoch 183/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9799 - dice_coef: 0.9799 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 184/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9800 - dice_coef: 0.9800 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 185/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9799 - dice_coef: 0.9799 - val_loss: -0.9722 - val_dice_coef: 0.9722\n",
      "Epoch 186/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9798 - dice_coef: 0.9798 - val_loss: -0.9732 - val_dice_coef: 0.9732\n",
      "Epoch 187/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9799 - dice_coef: 0.9799 - val_loss: -0.9705 - val_dice_coef: 0.9705\n",
      "Epoch 188/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9802 - dice_coef: 0.9802 - val_loss: -0.9740 - val_dice_coef: 0.9740\n",
      "Epoch 189/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9804 - dice_coef: 0.9804 - val_loss: -0.9728 - val_dice_coef: 0.9728\n",
      "Epoch 190/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9799 - dice_coef: 0.9799 - val_loss: -0.9717 - val_dice_coef: 0.9717\n",
      "Epoch 191/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9804 - dice_coef: 0.9804 - val_loss: -0.9735 - val_dice_coef: 0.9735\n",
      "Epoch 192/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9803 - dice_coef: 0.9803 - val_loss: -0.9721 - val_dice_coef: 0.9721\n",
      "Epoch 193/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9802 - dice_coef: 0.9802 - val_loss: -0.9713 - val_dice_coef: 0.9713\n",
      "Epoch 194/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9802 - dice_coef: 0.9802 - val_loss: -0.9743 - val_dice_coef: 0.9743\n",
      "Epoch 195/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9805 - dice_coef: 0.9805 - val_loss: -0.9723 - val_dice_coef: 0.9723\n",
      "Epoch 196/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9802 - dice_coef: 0.9802 - val_loss: -0.9734 - val_dice_coef: 0.9734\n",
      "Epoch 197/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9805 - dice_coef: 0.9805 - val_loss: -0.9736 - val_dice_coef: 0.9736\n",
      "Epoch 198/200\n",
      "14168/14168 [==============================] - 571s 40ms/step - loss: -0.9806 - dice_coef: 0.9806 - val_loss: -0.9742 - val_dice_coef: 0.9742\n",
      "Epoch 199/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9807 - dice_coef: 0.9807 - val_loss: -0.9744 - val_dice_coef: 0.9744\n",
      "Epoch 200/200\n",
      "14168/14168 [==============================] - 572s 40ms/step - loss: -0.9807 - dice_coef: 0.9807 - val_loss: -0.9730 - val_dice_coef: 0.9730\n"
     ]
    }
   ],
   "source": [
    "    # トレーニングを開始\n",
    "    epochs = 200\n",
    "    \n",
    "    if VALIDATION == 1:\n",
    "        print('start training...')\n",
    "        history = model_fcn00.fit(X_train[:,:,:,:], Y_train[:,:,:,:], batch_size=32, epochs=epochs, verbose=1,\n",
    "                      shuffle=True, validation_data=(X_valid, Y_valid), callbacks=[checkpointer])\n",
    "    else:\n",
    "        print('start training...')\n",
    "        history = model_fcn00.fit(X_train[:,:,:,:], Y_train[:,:,:,:], batch_size=32, epochs=epochs, verbose=1,\n",
    "                    shuffle=True, validation_split=0.1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Save History\n",
    "    f = open(dname_checkpoints + '/' + fname_history,'wb')\n",
    "    pickle.dump(history.history,f)\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints_fcn00.augumented_2/history.pkl\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-66838d064e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    #   Show History\n",
    "    #\n",
    "\n",
    "    # load pickle\n",
    "    print(dname_checkpoints + '/' + fname_history)\n",
    "    history = pickle.load(open(dname_checkpoints + '/' + fname_history, 'rb'))\n",
    "\n",
    "    for k in history.keys():\n",
    "        plt.plot(history[k])\n",
    "        plt.title(k)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
